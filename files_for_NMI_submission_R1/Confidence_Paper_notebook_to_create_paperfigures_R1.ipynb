{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["9XWTVD3WL_G3","kdHXz6qvdN0b","SqsotGuQNhaf","AI4HE03EtEpX","grVpLtdAIWPM","vFu6itMcIdBf","sZ7WsXFxIgEb","0nXdoHKzlP-O"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"qxxn1r1EH9Wj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpMkx8vAH0v1"},"outputs":[],"source":["import pandas as pd\n","import jax\n","import jax.numpy as jnp\n","import json\n","import os\n","import matplotlib.pyplot as plt\n","import random\n","import numpy as np\n","import seaborn as sns\n","\n","import scipy.stats as stats\n","from IPython.display import HTML, display, Image\n","from IPython.display import display\n","from scipy.optimize import curve_fit\n","from scipy.stats import binned_statistic\n","from sklearn.metrics import r2_score\n","\n","sns.set(style=\"white\", context=\"talk\")\n","\n","#for bayesian model\n","!pip install pymc arviz --quiet\n","import pymc as pm\n","import arviz as az\n","from matplotlib.ticker import MaxNLocator\n","from scipy.special import expit\n","from scipy.stats import linregress\n","from sklearn.metrics import roc_auc_score"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","tmp_dir = \"/content/drive/MyDrive/\"\n","drive.mount(\"/content/drive\", force_remount=True)"],"metadata":{"id":"vhJVx5_EIBqX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["the_dir = \"/content/drive/MyDrive/files_for_NMI_submission_R1/\"\n","the_old_dir = \"/content/drive/MyDrive/\""],"metadata":{"id":"RQTqlHRQyNVD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"9XWTVD3WL_G3"}},{"cell_type":"code","source":["#Find NaNs and get rid of those rows\n","\n","def find_nan_in_df(df):\n","    \"\"\"\n","    Searches a Pandas DataFrame for NaN values and reports their locations.\n","\n","    Args:\n","        df: The Pandas DataFrame to search.\n","\n","    Returns:\n","        None. Prints information about found NaN values.\n","    \"\"\"\n","    if df.isna().any().any():\n","\n","        nan_mask = df.isna()\n","        total_nans = df.isna().sum().sum()\n","        rows_with_nan = df[df.isna().any(axis=1)]\n","        num_rows_with_nan = len(rows_with_nan)\n","        df_no_nans = df.dropna()\n","    else:\n","\n","        df_no_nans = df  # <-- ADD THIS LINE\n","\n","    return df_no_nans"],"metadata":{"id":"aW-b9NhNL-vH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_new_confidence_columns(df, expt_type):\n","\n","    # Rename columns\n","    df = df.rename(columns={\n","        \"change_of_mind_actual\": \"change_of_mind\",\n","        \"other_llm_answer_shown\": \"other_llm_answer\",\n","        \"other_LLM_answer\": \"other_llm_answer\",\n","        \"other_LLM_accuracy\": \"other_llm_accuracy\",\n","        \"initial_confidence_a\": \"confidence_a\",\n","        \"initial_confidence_b\": \"confidence_b\"\n","    })\n","\n","    def get_initial_confidence_chosen(row):\n","        if row['initial_answer'] == 'a':\n","            return row['confidence_a']\n","        elif row['initial_answer'] == 'b':\n","            return row['confidence_b']\n","        else:\n","            return np.nan\n","\n","    def get_initial_confidence_final_chosen(row):\n","        if row['final_answer'] == 'a':\n","            return row['confidence_a']\n","        elif row['final_answer'] == 'b':\n","            return row['confidence_b']\n","        else:\n","            return np.nan\n","\n","    def get_confidence_difference(row):\n","        if row['initial_answer'] == 'a':\n","            return row['second_turn_confidence_a'] - row['initial_confidence_chosen']\n","        elif row['initial_answer'] == 'b':\n","            return row['second_turn_confidence_b'] - row['initial_confidence_chosen']\n","        else:\n","            return np.nan\n","\n","    def get_second_turn_confidence_initial_chosen_lat(row):\n","        if row['initial_answer'] == 'a':\n","            return row['second_turn_confidence_a']\n","        elif row['initial_answer'] == 'b':\n","            return row['second_turn_confidence_b']\n","        else:\n","            return np.nan\n","\n","    def get_second_turn_confidence_final_chosen_lat(row):\n","        if row['final_answer'] == 'a':\n","            return row['second_turn_confidence_a']\n","        elif row['final_answer'] == 'b':\n","            return row['second_turn_confidence_b']\n","        else:\n","            return np.nan\n","\n","    # Add new columns\n","    df['initial_confidence_chosen'] = df.apply(get_initial_confidence_chosen, axis=1)\n","    df['initial_confidence_final_chosen'] = df.apply(get_initial_confidence_final_chosen, axis=1)\n","    df['confidence_difference'] = df.apply(get_confidence_difference, axis=1)\n","    df['second_turn_binary_correctness'] = (df['final_answer'] == df['gt_answer']).astype(int)\n","    df['second_turn_confidence_initial_chosen'] = df.apply(get_second_turn_confidence_initial_chosen_lat, axis=1)\n","    df['second_turn_confidence_final_chosen'] = df.apply(get_second_turn_confidence_final_chosen_lat, axis=1)\n","    df['confidence_gap_initial'] = df['second_turn_confidence_initial_chosen'] - df['initial_confidence_chosen']\n","    df['confidence_gap_initial_chosen'] = df['second_turn_confidence_initial_chosen'] - df['initial_confidence_chosen']\n","\n","    # Answer Wrong -specific columns\n","    if expt_type == 'hog':\n","        # Set second_turn_confidence_hog_chosen based on hog answer\n","        df['second_turn_confidence_hog_chosen'] = df.apply(\n","            lambda row: row['second_turn_confidence_a'] if row['initial_answer_hog'] == 'a' else row['second_turn_confidence_b'],\n","            axis=1\n","        )\n","\n","        def get_initial_confidence_hog_chosen(row):\n","            if row['initial_answer_hog'] == 'a':\n","                return row['confidence_a']\n","            elif row['initial_answer_hog'] == 'b':\n","                return row['confidence_b']\n","            else:\n","                return np.nan\n","\n","        df['initial_confidence_hog_chosen'] = df.apply(get_initial_confidence_hog_chosen, axis=1)\n","        df['confidence_gap_hog_chosen'] = df['second_turn_confidence_hog_chosen'] - df['initial_confidence_hog_chosen']\n","\n","    return df"],"metadata":{"id":"UpwZZZXKMg8G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_new_confidence_columns_log_odds_space(df, expt_type):\n","\n","    # Convert from probability to log odds if needed\n","    epsilon = 1e-9\n","    for col in ['confidence_a', 'confidence_b', 'second_turn_confidence_a', 'second_turn_confidence_b']:\n","        clipped_prob = df[col].clip(lower=epsilon, upper=1-epsilon)\n","        df[f'{col}_log_odds'] = np.log(clipped_prob / (1 - clipped_prob))\n","\n","\n","    def get_confidence_for_answer(row, answer_col, conf_a_col, conf_b_col):\n","        \"\"\"Get confidence value based on answer choice (a or b)\"\"\"\n","        if row[answer_col] == 'a':\n","            return row[conf_a_col]\n","        elif row[answer_col] == 'b':\n","            return row[conf_b_col]\n","        else:\n","            return np.nan\n","\n","    # 1. Initial confidence for chosen answer\n","    df['initial_confidence_chosen_log_odds'] = df.apply(\n","        lambda row: get_confidence_for_answer(\n","            row, 'initial_answer',\n","            'confidence_a_log_odds',\n","            'confidence_b_log_odds'\n","        ), axis=1\n","    )\n","\n","    # 2. Initial confidence for final chosen answer\n","    df['initial_confidence_final_chosen_log_odds'] = df.apply(\n","        lambda row: get_confidence_for_answer(\n","            row, 'final_answer',\n","            'confidence_a_log_odds',\n","            'confidence_b_log_odds'\n","        ), axis=1\n","    )\n","\n","    # 3. Second turn confidence for initially chosen option\n","    df['second_turn_confidence_initial_chosen_log_odds'] = df.apply(\n","        lambda row: get_confidence_for_answer(\n","            row, 'initial_answer',\n","            'second_turn_confidence_a_log_odds',\n","            'second_turn_confidence_b_log_odds'\n","        ), axis=1\n","    )\n","\n","    # 4. Second turn confidence for final chosen answer\n","    df['second_turn_confidence_final_chosen_log_odds'] = df.apply(\n","        lambda row: get_confidence_for_answer(\n","            row, 'final_answer',\n","            'second_turn_confidence_a_log_odds',\n","            'second_turn_confidence_b_log_odds'\n","        ), axis=1\n","    )\n","\n","    # 5. Confidence difference (change in confidence for initially chosen option)\n","    df['confidence_difference_log_odds'] = (\n","        df['second_turn_confidence_initial_chosen_log_odds'] -\n","        df['initial_confidence_chosen_log_odds']\n","    )\n","\n","    # 6. Confidence gap (same as confidence_difference - redundant but keeping for compatibility)\n","    df['confidence_gap_initial_log_odds'] = (\n","        df['second_turn_confidence_initial_chosen_log_odds'] -\n","        df['initial_confidence_chosen_log_odds']\n","    )\n","\n","    # 7. Another redundant column with same calculation\n","    df['confidence_gap_initial_chosen_log_odds'] = (\n","        df['second_turn_confidence_initial_chosen_log_odds'] -\n","        df['initial_confidence_chosen_log_odds']\n","    )\n","\n","    # Conditional columns for answer wrong experiment type\n","    if expt_type == 'hog':\n","        # Initial confidence for hog chosen answer\n","        df['initial_confidence_hog_chosen_log_odds'] = df.apply(\n","            lambda row: get_confidence_for_answer(\n","                row, 'initial_answer_hog',\n","                'confidence_a_log_odds',\n","                'confidence_b_log_odds'\n","            ), axis=1\n","        )\n","\n","        # Second turn confidence for hog chosen answer\n","        df['second_turn_confidence_hog_chosen_log_odds'] = df.apply(\n","            lambda row: get_confidence_for_answer(\n","                row, 'initial_answer_hog',\n","                'second_turn_confidence_a_log_odds',\n","                'second_turn_confidence_b_log_odds'\n","            ), axis=1\n","        )\n","\n","        # Confidence gap for hog chosen answer\n","        df['confidence_gap_hog_chosen_log_odds'] = (\n","            df['second_turn_confidence_hog_chosen_log_odds'] -\n","            df['initial_confidence_hog_chosen_log_odds']\n","        )\n","\n","    return df"],"metadata":{"id":"PdezIIcBNPg-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_new_confidence_columns_4_choice(df, expt_type=\"standard\"):\n","    import pandas as pd\n","    import numpy as np\n","\n","    df = df.copy()\n","\n","    df = df.rename(columns={\"change_of_mind_actual\": \"change_of_mind\"})\n","    df = df.rename(columns={\"other_llm_answer_shown\": \"other_llm_answer\"})\n","    df = df.rename(columns={\"other_LLM_answer\": \"other_llm_answer\"})\n","    df = df.rename(columns={\"other_LLM_accuracy\": \"other_llm_accuracy\"})\n","\n","    for i in range(1, 5):\n","        if f\"initial_confidence_{i}\" in df.columns:\n","            df = df.rename(columns={f\"initial_confidence_{i}\": f\"confidence_{i}\"})\n","\n","    def safe_int_convert(value):\n","        if pd.isna(value):\n","            return None\n","        try:\n","            return int(float(value))\n","        except:\n","            return None\n","\n","    def get_initial_confidence_chosen(row):\n","        answer = safe_int_convert(row['initial_answer'])\n","        if answer in [1, 2, 3, 4]:\n","            col_name = f'confidence_{answer}'\n","            if col_name in row.index:\n","                return row[col_name]\n","        return np.nan\n","\n","    def get_initial_confidence_final_chosen(row):\n","        answer = safe_int_convert(row['final_answer'])\n","        if answer in [1, 2, 3, 4]:\n","            col_name = f'confidence_{answer}'\n","            if col_name in row.index:\n","                return row[col_name]\n","        return np.nan\n","\n","    def get_second_turn_confidence_initial_chosen(row):\n","        answer = safe_int_convert(row['initial_answer'])\n","        if answer in [1, 2, 3, 4]:\n","            col_name = f'second_turn_confidence_{answer}'\n","            if col_name in row.index:\n","                return row[col_name]\n","        return np.nan\n","\n","    def get_second_turn_confidence_final_chosen(row):\n","        answer = safe_int_convert(row['final_answer'])\n","        if answer in [1, 2, 3, 4]:\n","            col_name = f'second_turn_confidence_{answer}'\n","            if col_name in row.index:\n","                return row[col_name]\n","        return np.nan\n","\n","    def get_confidence_difference(row):\n","        initial_conf = row['initial_confidence_chosen']\n","        second_conf = row['second_turn_confidence_initial_chosen']\n","        if pd.notna(initial_conf) and pd.notna(second_conf):\n","            return second_conf - initial_conf\n","        return np.nan\n","\n","    df['initial_confidence_chosen'] = df.apply(get_initial_confidence_chosen, axis=1)\n","    df['initial_confidence_final_chosen'] = df.apply(get_initial_confidence_final_chosen, axis=1)\n","    df['second_turn_confidence_initial_chosen'] = df.apply(get_second_turn_confidence_initial_chosen, axis=1)\n","    df['second_turn_confidence_final_chosen'] = df.apply(get_second_turn_confidence_final_chosen, axis=1)\n","    df['confidence_difference'] = df.apply(get_confidence_difference, axis=1)\n","    df['confidence_gap_initial'] = df['confidence_difference']\n","    df['confidence_gap_initial_chosen'] = df['confidence_difference']\n","\n","    df['second_turn_binary_correctness'] = (df['final_answer'] == df['gt_answer']).astype(int)\n","\n","    if expt_type == 'hog':\n","        def get_second_turn_confidence_hog(row):\n","            hog_answer = safe_int_convert(row['initial_answer_hog'])\n","            if hog_answer in [1, 2, 3, 4]:\n","                return row[f'second_turn_confidence_{hog_answer}']\n","            return np.nan\n","\n","        def get_initial_confidence_hog_chosen(row):\n","            answer = safe_int_convert(row['initial_answer_hog'])\n","            if answer in [1, 2, 3, 4]:\n","                return row[f'confidence_{answer}']\n","            return np.nan\n","\n","        df['second_turn_confidence_hog_chosen'] = df.apply(get_second_turn_confidence_hog, axis=1)\n","        df['initial_confidence_hog_chosen'] = df.apply(get_initial_confidence_hog_chosen, axis=1)\n","        df['confidence_gap_hog_chosen'] = df['second_turn_confidence_hog_chosen'] - df['initial_confidence_hog_chosen']\n","\n","    return df"],"metadata":{"id":"lPV1vTnaohoM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_bayes_optimal_columns(df, n_alt_choices=1):\n","\n","    def calculate_bayes_probability(initial_confidence, initial_answer, final_answer,\n","                                    other_llm_answer_type, other_llm_accuracy,\n","                                    expt_type, other_llm_answer=None, initial_answer_hog=None):\n","        # Normalize prior confidence\n","        probabilities = initial_confidence.copy()\n","        prob_sum = sum(probabilities)\n","        probabilities = [p / prob_sum for p in probabilities] if prob_sum > 0 else [0.5, 0.5]\n","\n","        accuracy = other_llm_accuracy  # should be in [0, 1]\n","\n","        # Determine advisor's recommendation\n","        if other_llm_answer_type == \"Same\":\n","            advisor_recommendation = initial_answer_hog if expt_type == \"hog\" else initial_answer\n","            likelihood_given_advice = [\n","                accuracy if i == advisor_recommendation else (1 - accuracy) for i in range(2)\n","            ]\n","\n","        elif other_llm_answer_type == \"Opposite\":\n","            if other_llm_answer is None:\n","                advisor_recommendation = 1 - (initial_answer_hog if expt_type == \"hog\" else initial_answer)\n","            else:\n","                advisor_recommendation = other_llm_answer\n","            likelihood_given_advice = [\n","                accuracy if i == advisor_recommendation else (1 - accuracy) for i in range(2)\n","            ]\n","\n","        elif other_llm_answer_type == \"Nothing\":\n","            posterior_probabilities = probabilities\n","            likelihood_given_advice = None\n","\n","        else:\n","            raise ValueError(\"Invalid other_llm_answer_type. Must be 'Same', 'Opposite', or 'Nothing'.\")\n","\n","        # Compute Bayesian posterior\n","        if other_llm_answer_type != \"Nothing\":\n","            denominator = sum(likelihood_given_advice[i] * probabilities[i] for i in range(2))\n","            posterior_probabilities = [\n","                (likelihood_given_advice[i] * probabilities[i]) / denominator if denominator > 0 else 0.5\n","                for i in range(2)\n","            ]\n","\n","\n","        result = {\n","            \"bayes_optimal_probability_a\": posterior_probabilities[0],\n","            \"bayes_optimal_probability_b\": posterior_probabilities[1],\n","            \"bayes_optimal_probability_initial_chosen\": posterior_probabilities[initial_answer],\n","            \"bayes_optimal_probability_final_chosen\": posterior_probabilities[final_answer],\n","        }\n","\n","        if expt_type == \"hog\" and initial_answer_hog is not None:\n","            result[\"bayes_optimal_probability_hog_chosen\"] = posterior_probabilities[initial_answer_hog]\n","\n","        return result\n","\n","    def apply_bayes_calculation(row):\n","        expt_type = row['initial_answer_display']  # 'shown', 'hidden', or 'hog' (hog = answer wrong)\n","\n","        # Translate answers to index: 'a' → 0, 'b' → 1\n","        initial_answer_index = 0 if row['initial_answer'].lower() == 'a' else 1\n","        final_answer_index = 0 if row['final_answer'].lower() == 'a' else 1\n","\n","        if pd.notna(row['other_llm_answer']) and row['other_llm_answer_type'] == \"Opposite\":\n","            other_llm_answer_index = 0 if row['other_llm_answer'].lower() == 'a' else 1\n","        else:\n","            other_llm_answer_index = None\n","\n","        if expt_type == \"hog\" and pd.notna(row.get('initial_answer_hog', None)):\n","            initial_answer_hog_index = 0 if row['initial_answer_hog'].lower() == 'a' else 1\n","        else:\n","            initial_answer_hog_index = None\n","\n","        return calculate_bayes_probability(\n","            initial_confidence=[row['confidence_a'], row['confidence_b']],\n","            initial_answer=initial_answer_index,\n","            final_answer=final_answer_index,\n","            other_llm_answer_type=row['other_llm_answer_type'],\n","            other_llm_accuracy=row['other_llm_accuracy'] / 100.0,\n","            other_llm_answer=other_llm_answer_index,\n","            initial_answer_hog=initial_answer_hog_index,\n","            expt_type=expt_type\n","        )\n","\n","\n","    bayes_results = df.apply(apply_bayes_calculation, axis=1, result_type='expand')\n","\n","\n","    df = pd.concat([df, bayes_results], axis=1)\n","\n","    return df"],"metadata":{"id":"wiAvCzLqWDAI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_bayes_optimal_columns_4_choice(df):\n","    import pandas as pd\n","    import numpy as np\n","\n","    def calculate_bayes_probability(initial_confidence, initial_answer, final_answer,\n","                                    other_llm_answer_type, other_llm_accuracy,\n","                                    other_llm_answer=None):\n","        probabilities = initial_confidence.copy()\n","        prob_sum = sum(probabilities)\n","        if prob_sum > 0:\n","            probabilities = [p / prob_sum for p in probabilities]\n","        else:\n","            probabilities = [0.25, 0.25, 0.25, 0.25]\n","\n","        prob_sum = sum(probabilities)\n","        probabilities = [p / prob_sum for p in probabilities]\n","\n","        accuracy = other_llm_accuracy\n","\n","        if other_llm_answer_type == \"Nothing\":\n","            posterior_probabilities = probabilities\n","\n","        elif other_llm_answer_type in [\"Same\", \"Opposite\"]:\n","            if other_llm_answer is None:\n","                raise ValueError(f\"For '{other_llm_answer_type}' advice type, other_llm_answer must be provided\")\n","\n","            advisor_recommendation = other_llm_answer\n","\n","            likelihood_given_advice = []\n","            for i in range(4):\n","                if i == advisor_recommendation:\n","                    likelihood_given_advice.append(accuracy)\n","                else:\n","                    likelihood_given_advice.append((1 - accuracy) / 3)\n","\n","            denominator = sum(likelihood_given_advice[i] * probabilities[i] for i in range(4))\n","\n","            if denominator > 0:\n","                posterior_probabilities = [\n","                    (likelihood_given_advice[i] * probabilities[i]) / denominator\n","                    for i in range(4)\n","                ]\n","            else:\n","                posterior_probabilities = [0.25, 0.25, 0.25, 0.25]\n","\n","            post_sum = sum(posterior_probabilities)\n","            posterior_probabilities = [p / post_sum for p in posterior_probabilities]\n","\n","        else:\n","            raise ValueError(\"Invalid other_llm_answer_type. Must be 'Same', 'Opposite', or 'Nothing'.\")\n","\n","        result = {\n","            \"bayes_optimal_probability_1\": posterior_probabilities[0],\n","            \"bayes_optimal_probability_2\": posterior_probabilities[1],\n","            \"bayes_optimal_probability_3\": posterior_probabilities[2],\n","            \"bayes_optimal_probability_4\": posterior_probabilities[3],\n","            \"bayes_optimal_probability_initial_chosen\": posterior_probabilities[initial_answer],\n","            \"bayes_optimal_probability_final_chosen\": posterior_probabilities[final_answer],\n","        }\n","\n","        return result\n","\n","    def apply_bayes_calculation(row):\n","        def answer_to_index(answer):\n","            if pd.isna(answer):\n","                return None\n","            try:\n","                ans = int(float(answer))\n","                return ans - 1 if 1 <= ans <= 4 else None\n","            except:\n","                return None\n","\n","        initial_answer_index = answer_to_index(row['initial_answer'])\n","        final_answer_index = answer_to_index(row['final_answer'])\n","\n","        if pd.notna(row.get('other_llm_answer')):\n","            other_llm_answer_index = answer_to_index(row['other_llm_answer'])\n","        else:\n","            other_llm_answer_index = None\n","\n","        if initial_answer_index is None or final_answer_index is None:\n","            return {\n","                \"bayes_optimal_probability_1\": np.nan,\n","                \"bayes_optimal_probability_2\": np.nan,\n","                \"bayes_optimal_probability_3\": np.nan,\n","                \"bayes_optimal_probability_4\": np.nan,\n","                \"bayes_optimal_probability_initial_chosen\": np.nan,\n","                \"bayes_optimal_probability_final_chosen\": np.nan\n","            }\n","\n","        initial_confidence = [\n","            row.get('confidence_1', 0),\n","            row.get('confidence_2', 0),\n","            row.get('confidence_3', 0),\n","            row.get('confidence_4', 0)\n","        ]\n","\n","        other_llm_accuracy = row['other_llm_accuracy'] / 100.0\n","\n","        try:\n","            return calculate_bayes_probability(\n","                initial_confidence=initial_confidence,\n","                initial_answer=initial_answer_index,\n","                final_answer=final_answer_index,\n","                other_llm_answer_type=row['other_llm_answer_type'],\n","                other_llm_accuracy=other_llm_accuracy,\n","                other_llm_answer=other_llm_answer_index\n","            )\n","        except:\n","            return {\n","                \"bayes_optimal_probability_1\": np.nan,\n","                \"bayes_optimal_probability_2\": np.nan,\n","                \"bayes_optimal_probability_3\": np.nan,\n","                \"bayes_optimal_probability_4\": np.nan,\n","                \"bayes_optimal_probability_initial_chosen\": np.nan,\n","                \"bayes_optimal_probability_final_chosen\": np.nan\n","            }\n","\n","    bayes_results = df.apply(apply_bayes_calculation, axis=1, result_type='expand')\n","    df = pd.concat([df, bayes_results], axis=1)\n","\n","    return df"],"metadata":{"id":"ok7ee1LanxdV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_bayes_optimal_columns_log_odds_space(df, calculate_deviations=True, print_summary=False):\n","\n","    # Epsilon to avoid log(0) or division by zero\n","    EPSILON = 1e-9\n","\n","    def calculate_bayes_log_odds(initial_log_odds_a, initial_log_odds_b,\n","                            initial_answer, final_answer,\n","                            other_llm_answer_type, other_llm_accuracy,\n","                            other_llm_answer=None,\n","                            initial_answer_hog=None,\n","                            expt_type=None):\n","\n","        # Convert accuracy to probability (it comes as percentage 0-100)\n","        if other_llm_accuracy > 1:\n","            accuracy = other_llm_accuracy / 100.0\n","        else:\n","            accuracy = other_llm_accuracy\n","\n","\n","        accuracy = np.clip(accuracy, EPSILON, 1 - EPSILON)\n","\n","\n","        if np.abs(accuracy - 0.5) < EPSILON:\n","            log_likelihood_ratio = 0.0\n","\n","            result = {\n","                \"bayes_optimal_log_odds_a\": initial_log_odds_a,\n","                \"bayes_optimal_log_odds_b\": initial_log_odds_b,\n","            }\n","\n","            # Add log odds for specific choices (no change from prior)\n","            if initial_answer.lower() == 'a':\n","                result[\"bayes_optimal_log_odds_initial_chosen\"] = initial_log_odds_a\n","            else:\n","                result[\"bayes_optimal_log_odds_initial_chosen\"] = initial_log_odds_b\n","\n","            if final_answer.lower() == 'a':\n","                result[\"bayes_optimal_log_odds_final_chosen\"] = initial_log_odds_a\n","            else:\n","                result[\"bayes_optimal_log_odds_final_chosen\"] = initial_log_odds_b\n","\n","            if expt_type == \"hog\" and initial_answer_hog is not None:\n","                if initial_answer_hog.lower() == 'a':\n","                    result[\"bayes_optimal_log_odds_hog_chosen\"] = initial_log_odds_a\n","                else:\n","                    result[\"bayes_optimal_log_odds_hog_chosen\"] = initial_log_odds_b\n","\n","            return result\n","\n","        # Map answer letters to indices\n","        answer_map = {'a': 0, 'b': 1}\n","        initial_idx = answer_map.get(initial_answer.lower(), 0)\n","        final_idx = answer_map.get(final_answer.lower(), 0)\n","\n","        prior_log_odds = initial_log_odds_a\n","\n","        # Calculate log likelihood ratio based on advice type\n","        if other_llm_answer_type == \"Same\":\n","            # Advisor recommends same as initial choice (or answer wrong choice if applicable)\n","            if expt_type == \"hog\" and initial_answer_hog is not None:\n","                advisor_choice = initial_answer_hog.lower()\n","            else:\n","                advisor_choice = initial_answer.lower()\n","\n","\n","            if advisor_choice == 'a':\n","\n","                log_likelihood_ratio = np.log(accuracy / (1 - accuracy))\n","            else:\n","                log_likelihood_ratio = np.log((1 - accuracy) / accuracy)\n","\n","        elif other_llm_answer_type == \"Opposite\":\n","\n","            if other_llm_answer is not None:\n","                advisor_choice = other_llm_answer.lower()\n","            else:\n","\n","                if expt_type == \"hog\" and initial_answer_hog is not None:\n","                    advisor_choice = 'b' if initial_answer_hog.lower() == 'a' else 'a'\n","                else:\n","                    advisor_choice = 'b' if initial_answer.lower() == 'a' else 'a'\n","\n","\n","            if advisor_choice == 'a':\n","                log_likelihood_ratio = np.log(accuracy / (1 - accuracy))\n","            else:\n","                log_likelihood_ratio = np.log((1 - accuracy) / accuracy)\n","\n","        elif other_llm_answer_type == \"Nothing\" or other_llm_answer_type == \"Neutral\":\n","\n","            log_likelihood_ratio = 0\n","\n","        else:\n","            raise ValueError(f\"Invalid other_llm_answer_type: {other_llm_answer_type}\")\n","\n","        # Calculate posterior log odds\n","        posterior_log_odds_a = prior_log_odds + log_likelihood_ratio\n","        posterior_log_odds_b = -posterior_log_odds_a  # Since log(P(b)/P(a)) = -log(P(a)/P(b))\n","\n","\n","        result = {\n","            \"bayes_optimal_log_odds_a\": posterior_log_odds_a,\n","            \"bayes_optimal_log_odds_b\": posterior_log_odds_b,\n","        }\n","\n","\n","        if initial_answer.lower() == 'a':\n","            result[\"bayes_optimal_log_odds_initial_chosen\"] = posterior_log_odds_a\n","        else:\n","            result[\"bayes_optimal_log_odds_initial_chosen\"] = posterior_log_odds_b\n","\n","        if final_answer.lower() == 'a':\n","            result[\"bayes_optimal_log_odds_final_chosen\"] = posterior_log_odds_a\n","        else:\n","            result[\"bayes_optimal_log_odds_final_chosen\"] = posterior_log_odds_b\n","\n","        # Handle Answer Wrong experiment type\n","        if expt_type == \"hog\" and initial_answer_hog is not None:\n","            if initial_answer_hog.lower() == 'a':\n","                result[\"bayes_optimal_log_odds_hog_chosen\"] = posterior_log_odds_a\n","            else:\n","                result[\"bayes_optimal_log_odds_hog_chosen\"] = posterior_log_odds_b\n","\n","        return result\n","\n","    def apply_bayes_log_odds_calculation(row):\n","\n","        expt_type = row.get('initial_answer_display', 'shown')\n","\n","        # Get other_llm_answer if provided and advice type is Opposite\n","        other_llm_answer = None\n","        if pd.notna(row.get('other_llm_answer')) and row['other_llm_answer_type'] == \"Opposite\":\n","            other_llm_answer = row['other_llm_answer']\n","\n","        # Get initial_answer_hog for Answer Wrong\n","        initial_answer_hog = None\n","        if expt_type == \"hog\" and pd.notna(row.get('initial_answer_hog')):\n","            initial_answer_hog = row['initial_answer_hog']\n","\n","        return calculate_bayes_log_odds(\n","            initial_log_odds_a=row['confidence_a_log_odds'],\n","            initial_log_odds_b=row['confidence_b_log_odds'],\n","            initial_answer=row['initial_answer'],\n","            final_answer=row['final_answer'],\n","            other_llm_answer_type=row['other_llm_answer_type'],\n","            other_llm_accuracy=row['other_llm_accuracy'],\n","            other_llm_answer=other_llm_answer,\n","            initial_answer_hog=initial_answer_hog,\n","            expt_type=expt_type\n","        )\n","\n","\n","    bayes_results = df.apply(apply_bayes_log_odds_calculation, axis=1, result_type='expand')\n","\n","\n","    df = pd.concat([df, bayes_results], axis=1)\n","\n","    if print_summary:\n","        print(\"Created Bayesian log odds columns:\")\n","        bayes_columns = [col for col in bayes_results.columns]\n","        for col in bayes_columns:\n","            print(f\"  - {col}\")\n","\n","    if calculate_deviations:\n","\n","        df['log_odds_deviation_initial'] = (\n","            df['second_turn_confidence_initial_chosen_log_odds'] -\n","            df['bayes_optimal_log_odds_initial_chosen']\n","        )\n","\n","        df['log_odds_deviation_final'] = (\n","            df['second_turn_confidence_final_chosen_log_odds'] -\n","            df['bayes_optimal_log_odds_final_chosen']\n","        )\n","\n","    return df"],"metadata":{"id":"7t2cFfrlWpNs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functions For Bayesian Model"],"metadata":{"id":"kdHXz6qvdN0b"}},{"cell_type":"code","source":["def preprocess_experiment_data(df):\n","\n","    def find_nan_in_df(df):\n","\n","        if df.isna().any().any():\n","\n","            total_nans = df.isna().sum().sum()\n","            rows_with_nan = df[df.isna().any(axis=1)]\n","            num_rows_with_nan = len(rows_with_nan)\n","\n","\n","\n","            df_no_nans = df.dropna()\n","\n","            return df_no_nans\n","        else:\n","\n","            return df\n","\n","    def get_first_turn_confidence_initial_chosen(row):\n","        if row['initial_answer'] in ['1', '2', '3', '4']:\n","            return row[f'confidence_{row[\"initial_answer\"]}']\n","        else:\n","            return np.nan\n","\n","    def get_second_turn_confidence_initial_chosen(row):\n","        if row['initial_answer'] in ['1', '2', '3', '4']:\n","            return row[f'second_turn_confidence_{row[\"initial_answer\"]}']\n","        else:\n","            return np.nan\n","\n","    def get_first_turn_confidence_final_chosen(row):\n","        if row['final_answer'] in ['1', '2', '3', '4']:\n","            return row[f'confidence_{row[\"final_answer\"]}']\n","        else:\n","            return np.nan\n","\n","    def get_second_turn_confidence_final_chosen(row):\n","        if row['final_answer'] in ['1', '2', '3', '4']:\n","            return row[f'second_turn_confidence_{row[\"final_answer\"]}']\n","        else:\n","            return np.nan\n","\n","    df = find_nan_in_df(df)\n","\n","    invalid_initial_answers = df[~df['initial_answer'].isin(['1', '2', '3', '4'])]\n","\n","    df['first_turn_confidence_initial_chosen'] = df.apply(get_first_turn_confidence_initial_chosen, axis=1)\n","    df['second_turn_confidence_initial_chosen'] = df.apply(get_second_turn_confidence_initial_chosen, axis=1)\n","    df['first_turn_confidence_final_chosen'] = df.apply(get_first_turn_confidence_final_chosen, axis=1)\n","    df['second_turn_confidence_final_chosen'] = df.apply(get_second_turn_confidence_final_chosen, axis=1)\n","\n","    df['second_turn_binary_correctness'] = (df['final_answer'] == df['gt_answer']).astype(int)\n","\n","\n","    direction_mapping = {\n","        \"Same\": 1,\n","        \"Opposite\": -1,\n","        \"Nothing\": 0\n","    }\n","    df['advice_direction'] = df['other_llm_answer_type'].replace(direction_mapping)\n","\n","\n","    confirmation_mapping = {\n","        \"Same\": 1,\n","        \"Opposite\": 0,\n","        \"Nothing\": 0\n","    }\n","    df['confirmation_flag'] = df['other_llm_answer_type'].replace(confirmation_mapping)\n","\n","\n","    shown_mapping = {\n","        \"shown\": 1,\n","        \"hidden\": 0\n","    }\n","    df['shown_flag'] = df['initial_answer_display'].replace(shown_mapping)\n","\n","\n","    df[\"final_answer\"] = df[\"final_answer\"].astype(int)\n","    df[\"initial_answer\"] = df[\"initial_answer\"].astype(int)\n","\n","    if 'other_LLM_answer' in df.columns:\n","        df.rename(columns={'other_LLM_answer': 'other_llm_answer'}, inplace=True)\n","\n","    df[\"other_llm_answer\"] = df[\"other_llm_answer\"].apply(\n","        lambda x: -1 if isinstance(x, str) and \"hidden from\" in x else x\n","    )\n","\n","    df[\"other_llm_answer\"] = pd.to_numeric(df[\"other_llm_answer\"], errors=\"coerce\")\n","\n","    df['other_llm_accuracy'] = df['other_llm_accuracy'] / 100  # RESCALE from percentage\n","\n","    epsilon_acc = 1e-9\n","    df[\"other_llm_accuracy_capped\"] = np.clip(\n","        df[\"other_llm_accuracy\"],\n","        a_min=epsilon_acc,\n","        a_max=1 - epsilon_acc\n","    )\n","\n","\n","    df['effective_other_llm_accuracy_capped'] = df.apply(\n","        lambda row: row['other_llm_accuracy_capped']\n","        if row['other_llm_answer_type'] in [\"Same\", \"Nothing\"]\n","        else 1 - row['other_llm_accuracy_capped'],\n","        axis=1\n","    )\n","\n","    df['advice_direction_final'] = np.where(\n","        np.abs(df['advice_direction']) < 0.001, 0,  # explicitly neutral remains neutral\n","        np.where(df['other_llm_answer'] == df['final_answer'], 1, -1)\n","    )\n","\n","    if 'change_of_mind' not in df.columns:\n","        df['change_of_mind'] = (df['initial_answer'] != df['final_answer']).astype(int)\n","\n","    new_columns = [\n","        'first_turn_confidence_initial_chosen',\n","        'second_turn_confidence_initial_chosen',\n","        'first_turn_confidence_final_chosen',\n","        'second_turn_confidence_final_chosen',\n","        'second_turn_binary_correctness',\n","        'advice_direction',\n","        'confirmation_flag',\n","        'shown_flag',\n","        'other_llm_accuracy_capped',\n","        'effective_other_llm_accuracy_capped',\n","        'advice_direction_final',\n","        'change_of_mind'\n","    ]\n","\n","    return df"],"metadata":{"id":"yDDLvvNddNWW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_condition_encoding(df, categorical_columns, separator=\"_\",\n","                            label_column=\"condition_label\",\n","                            index_column=\"condition_idx\",\n","                            return_mapping=True, verbose=False):\n","\n","\n","    df = df.copy()\n","    df[label_column] = df[categorical_columns].astype(str).agg(separator.join, axis=1)\n","    condition_labels = sorted(df[label_column].unique())\n","\n","    label_to_index = {label: i for i, label in enumerate(condition_labels)}\n","    index_to_label = {i: label for label, i in label_to_index.items()}\n","    df[index_column] = df[label_column].map(label_to_index)\n","\n","    if verbose:\n","        print(f\"Created condition encoding from columns: {categorical_columns}\")\n","        print(f\"Number of unique conditions: {len(condition_labels)}\")\n","        print(\"\\nCondition mapping:\")\n","        for label, idx in sorted(label_to_index.items(), key=lambda x: x[1]):\n","            count = (df[label_column] == label).sum()\n","            print(f\"  {idx}: {label} (n={count})\")\n","\n","    if return_mapping:\n","        return df, label_to_index, index_to_label\n","    else:\n","        return df\n","\n"],"metadata":{"id":"LV82uQsEfyEV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_train_test_split(df, n_train=10000, n_test=10000, train_seed=42, test_seed=123, verbose=False):\n","\n","    total_requested = n_train + n_test\n","    if total_requested > len(df):\n","        raise ValueError(f\"Requested {total_requested} samples ({n_train} train + {n_test} test) \"\n","                        f\"but only {len(df)} samples available in DataFrame\")\n","\n","    df_train = df.sample(n=n_train, random_state=train_seed)\n","    df_remaining = df.drop(df_train.index)\n","    if n_test > len(df_remaining):\n","        raise ValueError(f\"Requested {n_test} test samples but only {len(df_remaining)} \"\n","                        f\"samples remaining after training split\")\n","\n","    df_test = df_remaining.sample(n=n_test, random_state=test_seed)\n","    df_remaining = df_remaining.drop(df_test.index)\n","\n","    if verbose:\n","        print(f\"Dataset split complete:\")\n","        print(f\"  - Original data: {len(df):,} samples\")\n","        print(f\"  - Training set: {len(df_train):,} samples\")\n","        print(f\"  - Test set: {len(df_test):,} samples\")\n","        print(f\"  - Remaining unused: {len(df_remaining):,} samples\")\n","        print(f\"  - Total used: {len(df_train) + len(df_test):,} samples \"\n","              f\"({(len(df_train) + len(df_test)) / len(df) * 100:.1f}%)\")\n","\n","    return df_train, df_test, df_remaining"],"metadata":{"id":"Bf8za0vNePaJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model_predictions(df, trace_latent, prediction_types=['initial', 'final', 'switch'],\n","                              n_options=4, save_figures=False, figure_path=None,\n","                              show_plots=True, verbose=True):\n","\n","    def effective_advice_prob(advice_direction, advice_for_choice, advice_accuracy, n_options):\n","        return np.where(\n","            advice_direction == 0, 1.0 / n_options,\n","            np.where(advice_for_choice, advice_accuracy, (1 - advice_accuracy) / (n_options - 1))\n","        )\n","\n","    def rescale_advice_prob(effective_advice_prob, advice_direction):\n","        return np.where(\n","            advice_direction == 1, (effective_advice_prob - 0.25) / 0.75,\n","            np.where(advice_direction == -1, (0.25 - effective_advice_prob) / 0.25, 0)\n","        )\n","\n","    prior_conf_initial = df[\"first_turn_confidence_initial_chosen\"].values\n","    prior_conf_final = df[\"first_turn_confidence_final_chosen\"].values\n","    advice_accuracy = df[\"other_llm_accuracy_capped\"].values\n","    advice_direction = df[\"advice_direction\"].values\n","    other_llm_answer = df[\"other_llm_answer\"].values\n","    final_answer = df[\"final_answer\"].values\n","    initial_answer = df[\"initial_answer\"].values\n","    shown_flag = df[\"shown_flag\"].values\n","\n","    # Compute effective advice probabilities\n","    advice_for_initial_choice = (other_llm_answer == initial_answer)\n","    advice_for_final_choice = (other_llm_answer == final_answer)\n","\n","    effective_advice_prob_initial = effective_advice_prob(\n","        advice_direction, advice_for_initial_choice, advice_accuracy, n_options\n","    )\n","    effective_advice_prob_final = effective_advice_prob(\n","        advice_direction, advice_for_final_choice, advice_accuracy, n_options\n","    )\n","\n","    # Advice direction final\n","    advice_direction_final = np.where(\n","        advice_direction == 0, 0,\n","        np.where(other_llm_answer == final_answer, 1, -1)\n","    )\n","\n","    # Rescale probabilities\n","    effective_advice_prob_initial_rescaled = rescale_advice_prob(\n","        effective_advice_prob_initial, advice_direction\n","    )\n","    effective_advice_prob_final_rescaled = rescale_advice_prob(\n","        effective_advice_prob_final, advice_direction_final\n","    )\n","\n","\n","    all_param_list = [\n","        \"intercept_final_conf\",\n","        \"intercept_initial_conf\",\n","        \"intercept_switch\",\n","        \"w_prior_shared\",\n","        \"w_shown_shared\",\n","        # Condition-specific weights for initial\n","        \"w_strength_initial_opposite_shown\",\n","        \"w_strength_initial_opposite_hidden\",\n","        \"w_strength_initial_same_shown\",\n","        \"w_strength_initial_same_hidden\",\n","        \"w_strength_initial_nothing\",\n","        # Weights for final\n","        \"w_strength_final_opposite\",\n","        \"w_strength_final_same\",\n","        \"w_strength_final_nothing\",\n","        # Weights for switching\n","        \"w_strength_COM_opposite\",\n","        \"w_strength_COM_same\",\n","        \"w_strength_COM_nothing\"\n","    ]\n","\n","    available_params = list(trace_latent.posterior.data_vars)\n","    params = {}\n","    for var in all_param_list:\n","        if var in available_params:\n","            params[var] = trace_latent.posterior[var].mean().values\n","\n","    if verbose:\n","        print(f\"Available parameters: {[p for p in all_param_list if p in params]}\")\n","\n","\n","    results = {}\n","\n","\n","    for prediction_type in prediction_types:\n","\n","        if prediction_type == 'initial':\n","            # Use condition-specific weights\n","            advice_strength = np.where(\n","                (advice_direction == 1) & (shown_flag == 1), params[\"w_strength_initial_same_shown\"],\n","                np.where((advice_direction == 1) & (shown_flag == 0), params[\"w_strength_initial_same_hidden\"],\n","                np.where((advice_direction == -1) & (shown_flag == 1), params[\"w_strength_initial_opposite_shown\"],\n","                np.where((advice_direction == -1) & (shown_flag == 0), params[\"w_strength_initial_opposite_hidden\"],\n","                params[\"w_strength_initial_nothing\"])))\n","            )\n","\n","            logit_post_conf = (\n","                params[\"intercept_initial_conf\"] +\n","                params[\"w_prior_shared\"] * prior_conf_initial +\n","                advice_strength * effective_advice_prob_initial_rescaled * advice_direction +\n","                params[\"w_shown_shared\"] * shown_flag\n","            )\n","\n","            predicted = expit(logit_post_conf)\n","            true_values = df[\"second_turn_confidence_initial_chosen\"].values\n","\n","\n","            r = np.corrcoef(predicted, true_values)[0, 1]\n","\n","            results['initial'] = {\n","                'predicted': predicted,\n","                'true': true_values,\n","                'correlation': r,\n","                'metric_name': 'Pearson r'\n","            }\n","\n","            if verbose:\n","                print(f\"\\nPearson r (initial): {r:.3f}\")\n","\n","\n","            if show_plots:\n","                plt.figure(figsize=(7, 5))\n","                plt.scatter(predicted, true_values, alpha=0.2)\n","\n","                slope, intercept, _, _, _ = linregress(predicted, true_values)\n","                plt.plot([0, 1], [intercept, intercept + slope], color='black')\n","                plt.legend([f\"Pearson's r = {r:.3f}\"], loc='upper left', fontsize=12)\n","\n","                plt.xlabel(\"Predicted Final Confidence in Initial Chosen\", fontsize=14)\n","                plt.ylabel(\"Observed Final Confidence\", fontsize=14)\n","                plt.xticks(fontsize=12)\n","                plt.yticks(fontsize=12)\n","                plt.xlim(0, 1)\n","                plt.ylim(0, 1)\n","                plt.tight_layout()\n","\n","                if save_figures and figure_path:\n","                    plt.savefig(f'{figure_path}/predicted_vs_actual_initial_condition_specific.png', dpi=300)\n","                plt.show()\n","\n","        elif prediction_type == 'final':\n","            # Simple weights for final\n","            advice_strength = np.where(\n","                advice_direction_final == 1, params[\"w_strength_final_same\"],\n","                np.where(advice_direction_final == -1, params[\"w_strength_final_opposite\"],\n","                params[\"w_strength_final_nothing\"])\n","            )\n","\n","            logit_post_conf = (\n","                params[\"intercept_final_conf\"] +\n","                params[\"w_prior_shared\"] * prior_conf_final +\n","                advice_strength * effective_advice_prob_final_rescaled * advice_direction_final +\n","                params[\"w_shown_shared\"] * shown_flag\n","            )\n","\n","            predicted = expit(logit_post_conf)\n","            true_values = df[\"second_turn_confidence_final_chosen\"].values\n","\n","\n","            r = np.corrcoef(predicted, true_values)[0, 1]\n","\n","            results['final'] = {\n","                'predicted': predicted,\n","                'true': true_values,\n","                'correlation': r,\n","                'metric_name': 'Pearson r'\n","            }\n","\n","            if verbose:\n","                print(f\"Pearson r (final): {r:.3f}\")\n","\n","\n","            if show_plots:\n","                plt.figure(figsize=(7, 5))\n","                plt.scatter(predicted, true_values, alpha=0.2)\n","\n","                slope, intercept, _, _, _ = linregress(predicted, true_values)\n","                plt.plot([0, 1], [intercept, intercept + slope], color='black')\n","                plt.legend([f\"Pearson's r = {r:.3f}\"], loc='upper left', fontsize=12)\n","\n","                plt.xlabel(\"Predicted Final Confidence in Final Chosen\", fontsize=14)\n","                plt.ylabel(\"Observed Final Confidence\", fontsize=14)\n","                plt.xticks(fontsize=12)\n","                plt.yticks(fontsize=12)\n","                plt.xlim(0, 1)\n","                plt.ylim(0, 1)\n","                plt.tight_layout()\n","\n","                if save_figures and figure_path:\n","                    plt.savefig(f'{figure_path}/predicted_vs_actual_final_condition_specific.png', dpi=300)\n","                plt.show()\n","\n","        elif prediction_type == 'switch':\n","            # Switching model\n","            switch_flag = df[\"change_of_mind\"].values\n","\n","            advice_strength_switching = np.where(\n","                advice_direction == 1, params[\"w_strength_COM_same\"],\n","                np.where(advice_direction == -1, params[\"w_strength_COM_opposite\"],\n","                params[\"w_strength_COM_nothing\"])\n","            )\n","\n","            L = (\n","                params[\"intercept_switch\"] +\n","                params[\"w_prior_shared\"] * prior_conf_initial +\n","                advice_strength_switching * effective_advice_prob_initial_rescaled * advice_direction +\n","                params[\"w_shown_shared\"] * shown_flag\n","            )\n","\n","            p_switch = expit(-L)\n","\n","            auc_score = roc_auc_score(switch_flag, p_switch)\n","\n","            results['switch'] = {\n","                'predicted': p_switch,\n","                'true': switch_flag,\n","                'auc': auc_score,\n","                'metric_name': 'ROC AUC'\n","            }\n","\n","            if verbose:\n","                print(f\"\\nAUC score: {auc_score:.3f}\")\n","\n","\n","            if show_plots:\n","                plt.figure(figsize=(7, 5))\n","                sns.histplot(p_switch[switch_flag == 0], color=\"blue\", label=\"Stay trials\",\n","                           kde=True, stat=\"density\", bins=np.linspace(0, 1, 30), alpha=0.6)\n","                sns.histplot(p_switch[switch_flag == 1], color=\"red\", label=\"Switch trials\",\n","                           kde=True, stat=\"density\", bins=np.linspace(0, 1, 30), alpha=0.6)\n","                plt.axvline(0.5, linestyle=\"--\", color=\"black\", alpha=0.7)\n","                plt.xlabel(\"Predicted Change of Mind Rate\", fontsize=14)\n","                plt.ylabel(\"Density\", fontsize=14)\n","                plt.xticks(fontsize=12)\n","                plt.yticks(fontsize=12)\n","                plt.legend([\"Stay trials\", \"Switch trials\", f\"ROC AUC: {auc_score:.3f}\"],\n","                          fontsize=10, frameon=False, loc='upper right')\n","\n","                sns.despine()\n","                plt.tight_layout()\n","\n","                if save_figures and figure_path:\n","                    plt.savefig(f'{figure_path}/predicted_switching_histogram.png', dpi=300)\n","                plt.show()\n","\n","    return results\n"],"metadata":{"id":"wBKuQO05fSIO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Plotting functions"],"metadata":{"id":"SqsotGuQNhaf"}},{"cell_type":"code","source":["def plot_change_of_mind_opposite(df,\n","                                     conditions=None,\n","                                     accuracies=None,\n","                                     available_display_types=None,\n","                                     colors=None,\n","                                     figsize_per_condition=(8, 6),\n","                                     save_figure=False,\n","                                     save_path=None,\n","                                     filename='Change_of_Mind_Plot.png',\n","                                     dpi=300):\n","\n","    if colors is None:\n","        colors = {'shown': 'tab:orange', 'hidden': 'tab:blue', 'hog': 'tab:green'}\n","\n","    if available_display_types is None:\n","        available_display_types = ['shown', 'hidden']\n","\n","    if conditions is None:\n","        conditions = ['Opposite']\n","\n","    if accuracies is None:\n","        accuracies = sorted(df['other_llm_accuracy'].unique())\n","\n","    fig, axes = plt.subplots(1, len(conditions),\n","                            figsize=(figsize_per_condition[0] * len(conditions), figsize_per_condition[1]),\n","                            squeeze=False)\n","\n","    for j, condition in enumerate(conditions):\n","        ax = axes[0, j]\n","\n","        bar_width = 0.35\n","        x = np.arange(len(accuracies))\n","\n","        for idx, display_type in enumerate(available_display_types):\n","            sub_df = df[\n","                (df['initial_answer_display'] == display_type) &\n","                (df['other_llm_answer_type'] == condition)\n","            ]\n","\n","            change_col = 'change_of_mind_hog' if display_type == 'hog' else 'change_of_mind'\n","            label = display_type.capitalize()\n","\n","            means = sub_df.groupby('other_llm_accuracy')[change_col].mean() * 100\n","            sems = sub_df.groupby('other_llm_accuracy')[change_col].sem() * 100\n","\n","            means = means.reindex(accuracies, fill_value=np.nan)\n","            sems = sems.reindex(accuracies, fill_value=0)\n","\n","            ax.bar(\n","                x + idx * bar_width,\n","                means,\n","                bar_width,\n","                yerr=sems,\n","                capsize=5,\n","                label=label,\n","                color=colors[display_type],\n","                alpha=0.8,\n","                edgecolor='black'\n","            )\n","\n","        display_condition = 'Neutral' if condition == 'Nothing' else condition\n","        ax.set_title(f'{display_condition} Advice')\n","\n","        ax.set_xlabel('LLM Accuracy (%)')\n","        ax.set_ylabel('Change of Mind (%)')\n","        ax.set_xticks(x + bar_width / 2)\n","        ax.set_xticklabels(accuracies)\n","        ax.set_ylim(-5, 105)\n","        ax.spines['top'].set_visible(False)\n","        ax.spines['right'].set_visible(False)\n","        ax.spines['bottom'].set_linewidth(1.2)\n","        ax.spines['left'].set_linewidth(1.2)\n","        ax.legend(title=\"Answer\")\n","\n","    plt.tight_layout()\n","\n","\n","    if save_figure and save_path:\n","        os.makedirs(save_path, exist_ok=True)\n","        fig.savefig(os.path.join(save_path, filename), dpi=dpi)\n","\n","    plt.show()\n","\n","    return fig, axes"],"metadata":{"id":"bXGH5gcLNkGT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_change_of_mind_by_condition(df,\n","                                     conditions=None,\n","                                     accuracies=None,\n","                                     available_display_types=None,\n","                                     colors=None,\n","                                     figsize_per_condition=(8, 6),\n","                                     save_figure=False,\n","                                     save_path=None,\n","                                     filename='Change_of_Mind_Plot.png',\n","                                     dpi=300):\n","\n","\n","\n","    if colors is None:\n","        colors = {'shown': 'tab:orange', 'hidden': 'tab:blue', 'hog': 'tab:green'}\n","\n","    if available_display_types is None:\n","        available_display_types = ['shown', 'hidden']\n","\n","    if conditions is None:\n","        conditions = ['Opposite', 'Same', 'Nothing']\n","\n","    if accuracies is None:\n","        accuracies = sorted(df['other_llm_accuracy'].unique())\n","\n","    # Create figure\n","    fig, axes = plt.subplots(1, len(conditions),\n","                            figsize=(figsize_per_condition[0] * len(conditions), figsize_per_condition[1]),\n","                            squeeze=False)\n","\n","    for j, condition in enumerate(conditions):\n","        ax = axes[0, j]\n","\n","        bar_width = 0.35\n","        x = np.arange(len(accuracies))\n","\n","        for idx, display_type in enumerate(available_display_types):\n","            sub_df = df[\n","                (df['initial_answer_display'] == display_type) &\n","                (df['other_llm_answer_type'] == condition)\n","            ]\n","\n","            change_col = 'change_of_mind_hog' if display_type == 'hog' else 'change_of_mind'\n","            label = display_type.capitalize()\n","\n","            means = sub_df.groupby('other_llm_accuracy')[change_col].mean() * 100\n","            sems = sub_df.groupby('other_llm_accuracy')[change_col].sem() * 100\n","\n","            means = means.reindex(accuracies, fill_value=np.nan)\n","            sems = sems.reindex(accuracies, fill_value=0)\n","\n","            ax.bar(\n","                x + idx * bar_width,\n","                means,\n","                bar_width,\n","                yerr=sems,\n","                capsize=5,\n","                label=label,\n","                color=colors[display_type],\n","                alpha=0.8,\n","                edgecolor='black'\n","            )\n","\n","\n","        display_condition = 'Neutral' if condition == 'Nothing' else condition\n","        ax.set_title(f'{display_condition} Advice')\n","\n","        ax.set_xlabel('LLM Accuracy (%)')\n","        ax.set_ylabel('Change of Mind (%)')\n","        ax.set_xticks(x + bar_width / 2)\n","        ax.set_xticklabels(accuracies)\n","        ax.set_ylim(-5, 105)\n","        ax.spines['top'].set_visible(False)\n","        ax.spines['right'].set_visible(False)\n","        ax.spines['bottom'].set_linewidth(1.2)\n","        ax.spines['left'].set_linewidth(1.2)\n","        ax.legend(title=\"Answer\")\n","\n","    plt.tight_layout()\n","\n","\n","    if save_figure and save_path:\n","        os.makedirs(save_path, exist_ok=True)\n","        fig.savefig(os.path.join(save_path, filename), dpi=dpi)\n","\n","    plt.show()\n","\n","    return fig, axes"],"metadata":{"id":"N33SDmD2a5lL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_confidence_change_by_condition(df,\n","                                       conditions=None,\n","                                       accuracies=None,\n","                                       available_display_types=None,\n","                                       colors=None,\n","                                       figsize_per_condition=(8, 6),\n","                                       save_figure=False,\n","                                       save_path=None,\n","                                       filename='Confidence_Change_Plot.png',\n","                                       dpi=300,\n","                                       show_legend_on='first'):\n","\n","    if colors is None:\n","        colors = {'shown': 'tab:orange', 'hidden': 'tab:blue', 'hog': 'tab:gray'}\n","\n","    if available_display_types is None:\n","        available_display_types = ['shown', 'hidden']\n","\n","    if conditions is None:\n","        conditions = ['Opposite', 'Same', 'Nothing']\n","\n","    if accuracies is None:\n","        accuracies = sorted(df['other_llm_accuracy'].unique())\n","\n","    fig, axes = plt.subplots(1, len(conditions),\n","                            figsize=(figsize_per_condition[0] * len(conditions), figsize_per_condition[1]),\n","                            squeeze=False)\n","\n","    for idx_c, condition in enumerate(conditions):\n","        ax = axes[0, idx_c]\n","\n","        bar_width = 0.35\n","        x = np.arange(len(accuracies))\n","\n","        for idx_d, display_type in enumerate(available_display_types):\n","            sub_df = df[\n","                (df['initial_answer_display'] == display_type) &\n","                (df['other_llm_answer_type'] == condition)\n","            ].copy()\n","\n","            sub_df['confidence_change'] = sub_df['second_turn_confidence_initial_chosen'] - sub_df['initial_confidence_chosen']\n","\n","            means = sub_df.groupby('other_llm_accuracy')['confidence_change'].mean()\n","            sems = sub_df.groupby('other_llm_accuracy')['confidence_change'].sem()\n","\n","            means = means.reindex(accuracies, fill_value=np.nan)\n","            sems = sems.reindex(accuracies, fill_value=0)\n","\n","            ax.bar(\n","                x + idx_d * bar_width,\n","                means,\n","                bar_width,\n","                yerr=sems,\n","                capsize=5,\n","                label=display_type.capitalize(),\n","                color=colors[display_type],\n","                alpha=0.8,\n","                edgecolor='black'\n","            )\n","\n","\n","        display_condition = 'Neutral' if condition == 'Nothing' else condition\n","        ax.set_title(f'{display_condition} Advice')\n","        ax.set_xlabel('Advice Accuracy (%)')\n","        ax.set_ylabel('Confidence Change')\n","        ax.set_xticks(x + bar_width / 2)\n","        ax.set_xticklabels(accuracies)\n","        ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n","\n","        ax.spines['top'].set_visible(False)\n","        ax.spines['right'].set_visible(False)\n","        ax.spines['bottom'].set_linewidth(1.2)\n","        ax.spines['left'].set_linewidth(1.2)\n","\n","\n","        if (show_legend_on == 'first' and idx_c == 0) or \\\n","           (show_legend_on == 'all') or \\\n","           (isinstance(show_legend_on, int) and idx_c == show_legend_on):\n","            ax.legend(title=\"Display Type\")\n","\n","    plt.tight_layout()\n","\n","    if save_figure and save_path:\n","        os.makedirs(save_path, exist_ok=True)\n","        fig.savefig(os.path.join(save_path, filename), dpi=dpi)\n","\n","    plt.show()\n","\n","    return fig, axes"],"metadata":{"id":"UStD2ENyQDNK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_confidence_change_log_odds_by_condition(df,\n","                                                conditions=None,\n","                                                accuracies=None,\n","                                                available_display_types=None,\n","                                                colors=None,\n","                                                figsize_per_condition=(8, 6),\n","                                                save_figure=False,\n","                                                save_path=None,\n","                                                filename='LogOdds_Confidence_Change_Plot.png',\n","                                                dpi=300,\n","                                                show_legend_on='first'):\n","\n","    if colors is None:\n","        colors = {'shown': 'tab:orange', 'hidden': 'tab:blue', 'hog': 'tab:gray'}\n","\n","    if available_display_types is None:\n","        available_display_types = ['shown', 'hidden']\n","\n","    if conditions is None:\n","        conditions = ['Opposite', 'Same', 'Nothing']\n","\n","    if accuracies is None:\n","        accuracies = sorted(df['other_llm_accuracy'].unique())\n","\n","    # Create composite plot\n","    fig, axes = plt.subplots(1, len(conditions),\n","                            figsize=(figsize_per_condition[0] * len(conditions), figsize_per_condition[1]),\n","                            squeeze=False)\n","\n","    for idx_c, condition in enumerate(conditions):\n","        ax = axes[0, idx_c]\n","\n","        bar_width = 0.35\n","        x = np.arange(len(accuracies))\n","\n","        for idx_d, display_type in enumerate(available_display_types):\n","            sub_df = df[\n","                (df['initial_answer_display'] == display_type) &\n","                (df['other_llm_answer_type'] == condition)\n","            ].copy()\n","\n","            sub_df['confidence_change_log_odds'] = sub_df['second_turn_confidence_initial_chosen_log_odds'] - sub_df['initial_confidence_chosen_log_odds']\n","\n","            means = sub_df.groupby('other_llm_accuracy')['confidence_change_log_odds'].mean()\n","            sems = sub_df.groupby('other_llm_accuracy')['confidence_change_log_odds'].sem()\n","\n","            means = means.reindex(accuracies, fill_value=np.nan)\n","            sems = sems.reindex(accuracies, fill_value=0)\n","\n","            ax.bar(\n","                x + idx_d * bar_width,\n","                means,\n","                bar_width,\n","                yerr=sems,\n","                capsize=5,\n","                label=display_type.capitalize(),\n","                color=colors[display_type],\n","                alpha=0.8,\n","                edgecolor='black'\n","            )\n","\n","\n","        display_condition = 'Neutral' if condition == 'Nothing' else condition\n","        ax.set_title(f'{display_condition} Advice')\n","        ax.set_xlabel('Advice Accuracy (%)')\n","        ax.set_ylabel('Log Odds Confidence Change')\n","        ax.set_xticks(x + bar_width / 2)\n","        ax.set_xticklabels(accuracies)\n","        ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n","\n","        ax.spines['top'].set_visible(False)\n","        ax.spines['right'].set_visible(False)\n","        ax.spines['bottom'].set_linewidth(1.2)\n","        ax.spines['left'].set_linewidth(1.2)\n","\n","\n","        if (show_legend_on == 'first' and idx_c == 0) or \\\n","           (show_legend_on == 'all') or \\\n","           (isinstance(show_legend_on, int) and idx_c == show_legend_on):\n","            ax.legend(title=\"Display Type\")\n","\n","    plt.tight_layout()\n","\n","    if save_figure and save_path:\n","        os.makedirs(save_path, exist_ok=True)\n","        fig.savefig(os.path.join(save_path, filename), dpi=dpi)\n","\n","    plt.show()\n","\n","    return fig, axes"],"metadata":{"id":"Vapzj3nWQt-A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_confidence_com_grid(df,\n","                            display_types_list=None,\n","                            conditions=None,\n","                            bin_width=0.05,\n","                            min_marker_size=10,\n","                            max_marker_size=400,\n","                            figsize_per_subplot=(6, 5),\n","                            save_figure=False,\n","                            save_path=None,\n","                            filename='confidence_COM_grid.png',\n","                            dpi=300,\n","                            marker_color='gray',\n","                            line_color='black',\n","                            marker_alpha=0.7):\n","\n","\n","\n","    bins = np.arange(0, 1 + bin_width, bin_width)\n","    bin_midpoints = bins[:-1] + bin_width/2\n","\n","\n","    if display_types_list is None:\n","        display_types_list = sorted(df['initial_answer_display'].unique())\n","\n","    if conditions is None:\n","        conditions = sorted(df['other_llm_answer_type'].unique())\n","\n","    # Calculate global min/max for marker sizing across all data\n","    global_counts = []\n","    for disp_type in display_types_list:\n","        for condition in conditions:\n","            sub_df = df.loc[(df['initial_answer_display'] == disp_type) &\n","                            (df['other_llm_answer_type'] == condition)].copy()\n","            conf_col = 'initial_confidence_hog_chosen' if disp_type == 'hog' else 'initial_confidence_chosen'\n","            sub_df['confidence_bin'] = pd.cut(sub_df[conf_col], bins, include_lowest=True, labels=bin_midpoints)\n","            counts = sub_df['confidence_bin'].value_counts().reindex(bin_midpoints, fill_value=0)\n","            global_counts.extend(counts.values)\n","\n","    global_min_count = np.min(global_counts) if global_counts else 0\n","    global_max_count = np.max(global_counts) if global_counts else 1\n","\n","\n","    fig, axes = plt.subplots(len(display_types_list), len(conditions),\n","                             figsize=(figsize_per_subplot[0] * len(conditions),\n","                                     figsize_per_subplot[1] * len(display_types_list)),\n","                             squeeze=False)\n","\n","    for i, disp_type in enumerate(display_types_list):\n","        for j, condition in enumerate(conditions):\n","            ax = axes[i, j]\n","\n","            sub_df = df.loc[(df['initial_answer_display'] == disp_type) &\n","                            (df['other_llm_answer_type'] == condition)].copy()\n","\n","            conf_col = 'initial_confidence_hog_chosen' if disp_type == 'hog' else 'initial_confidence_chosen'\n","            com_col = 'change_of_mind_hog' if disp_type == 'hog' else 'change_of_mind'\n","\n","            sub_df['confidence_bin'] = pd.cut(sub_df[conf_col], bins, include_lowest=True, labels=bin_midpoints)\n","\n","            mean_data = sub_df.groupby('confidence_bin', observed=True)[com_col].mean() * 100\n","            counts = sub_df['confidence_bin'].value_counts().reindex(bin_midpoints, fill_value=0)\n","\n","            mean_full = pd.Series(index=bin_midpoints, data=np.nan, dtype=float)\n","            mean_full.loc[mean_data.index.astype(float)] = mean_data.values\n","\n","            # Global normalization of marker size\n","            if global_max_count > global_min_count:\n","                norm_counts = (counts - global_min_count) / (global_max_count - global_min_count)\n","            else:\n","                norm_counts = pd.Series(0.5, index=counts.index)\n","\n","            sizes = min_marker_size + norm_counts * (max_marker_size - min_marker_size)\n","\n","            ax.scatter(bin_midpoints, mean_full.values, s=sizes,\n","                      color=marker_color, edgecolor='black', alpha=marker_alpha)\n","            ax.plot(bin_midpoints, mean_full.values, linestyle='-', color=line_color)\n","\n","            ax.set_xticks(np.arange(0, 1.1, 0.2))\n","            ax.set_yticks(np.arange(0, 101, 20))\n","            ax.set_xlabel('Confidence in Initial Chosen Option')\n","            ax.set_ylabel('Change of Mind Rate (%)')\n","            ax.set_xlim(0, 1)\n","            ax.set_ylim(-5, 105)\n","\n","\n","            display_label = 'Answer Hidden' if disp_type == 'hidden' else f'Answer {disp_type.capitalize()}'\n","            condition_label = 'Neutral' if condition == 'Nothing' else condition\n","            title = f\"{display_label} - {condition_label} Advice\"\n","            ax.set_title(title, fontsize=16, pad=12)\n","\n","            sns.despine(ax=ax)\n","\n","    plt.tight_layout()\n","\n","    if save_figure and save_path:\n","        os.makedirs(save_path, exist_ok=True)\n","        fig.savefig(os.path.join(save_path, filename), dpi=dpi)\n","\n","    plt.show()\n","\n","    return fig, axes"],"metadata":{"id":"nPZFkaj8Uuwh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_non_linear_threshold_OH_NH_COM_conf(df,\n","                                            focus_accuracies=None,\n","                                            min_bin_number=30,\n","                                            num_bins=15,\n","                                            save_figure=False,\n","                                            save_path=None,\n","                                            filename='sigmoid_plot_nothing_opp_hidden.png',\n","                                            figsize=(20, 8),\n","                                            curve_colors=None,\n","                                            font_size=18,\n","                                            show_summary=False):\n","\n","    import warnings\n","    warnings.filterwarnings('ignore')\n","\n","    if focus_accuracies is None:\n","        focus_accuracies = [50, 60, 70]\n","\n","    if curve_colors is None:\n","        curve_colors = ['#9b59b6', '#3498db', '#e67e22']  # Purple, blue, orange\n","\n","    # Define model functions\n","    def linear_func(x, a, b):\n","        return a * x + b\n","\n","    def sigmoid_func_constrained(x, a, b, c):\n","        \"\"\"Constrained sigmoid: always between 0 and a≤1\"\"\"\n","        return a / (1 + np.exp(-b * (x - c)))\n","\n","\n","    if show_summary:\n","        print(\"FITTING SIGMOID TO OPPOSITE HIDDEN DATA\")\n","        print(\"=\"*60)\n","\n","    opposite_hidden = df[(df['other_llm_answer_type'] == 'Opposite') &\n","                        (df['initial_answer_display'] == 'hidden') &\n","                        (df['other_llm_accuracy'].isin(focus_accuracies))].copy()\n","\n","    model_results = []\n","\n","    for accuracy in focus_accuracies:\n","        if show_summary:\n","            print(f\"\\nAnalyzing Opposite Hidden {accuracy}% accuracy...\")\n","\n","        data_subset = opposite_hidden[opposite_hidden['other_llm_accuracy'] == accuracy].copy()\n","\n","        if len(data_subset) == 0:\n","            if show_summary:\n","                print(f\"  No data for {accuracy}% accuracy\")\n","            continue\n","\n","        X = data_subset['initial_confidence_chosen'].values\n","        y = data_subset['change_of_mind'].values\n","\n","\n","        conf_bins = np.linspace(X.min(), X.max(), num_bins + 1)\n","        bin_centers = []\n","        bin_rates = []\n","        bin_counts = []\n","\n","        for i in range(len(conf_bins)-1):\n","            mask = (X >= conf_bins[i]) & (X < conf_bins[i+1])\n","            bin_data = y[mask]\n","            if len(bin_data) >= min_bin_number:\n","                bin_centers.append((conf_bins[i] + conf_bins[i+1]) / 2)\n","                bin_rates.append(bin_data.mean())\n","                bin_counts.append(len(bin_data))\n","\n","        bin_centers = np.array(bin_centers)\n","        bin_rates = np.array(bin_rates)\n","        bin_counts = np.array(bin_counts)\n","\n","        weights = np.sqrt(bin_counts)\n","\n","        results = {\n","            'accuracy': accuracy,\n","            'n_bins': len(bin_centers),\n","            'bin_centers': bin_centers,\n","            'bin_rates': bin_rates,\n","            'bin_sizes': bin_counts\n","        }\n","\n","\n","        try:\n","            bounds = ([0.01, -50, 0], [1.0, -0.1, 1])\n","            popt, _ = curve_fit(sigmoid_func_constrained, bin_centers, bin_rates,\n","                               p0=[0.8, -5, 0.5], sigma=1/weights,\n","                               bounds=bounds, maxfev=5000)\n","\n","            results['sigmoid_params'] = popt\n","            if show_summary:\n","                print(f\"  Sigmoid fit successful: a={popt[0]:.3f}, b={popt[1]:.3f}, c={popt[2]:.3f}\")\n","\n","        except Exception as e:\n","            if show_summary:\n","                print(f\"  Sigmoid fitting failed: {e}\")\n","            results['sigmoid_params'] = None\n","\n","        model_results.append(results)\n","\n","    if show_summary:\n","        print(\"\\n\\nFITTING LINEAR TO NOTHING HIDDEN DATA\")\n","        print(\"=\"*60)\n","\n","    nothing_hidden = df[(df['other_llm_answer_type'] == 'Nothing') &\n","                        (df['initial_answer_display'] == 'hidden') &\n","                        (df['other_llm_accuracy'].isin(focus_accuracies))].copy()\n","\n","    nothing_hidden_results = []\n","\n","    for accuracy in focus_accuracies:\n","        if show_summary:\n","            print(f\"\\nAnalyzing Nothing Hidden {accuracy}% accuracy...\")\n","\n","        data_subset = nothing_hidden[nothing_hidden['other_llm_accuracy'] == accuracy].copy()\n","\n","        if len(data_subset) == 0:\n","            if show_summary:\n","                print(f\"  No data for {accuracy}% accuracy\")\n","            continue\n","\n","        X = data_subset['initial_confidence_chosen'].values\n","        y = data_subset['change_of_mind'].values\n","\n","\n","        conf_bins = np.linspace(X.min(), X.max(), num_bins + 1)\n","        bin_centers = []\n","        bin_rates = []\n","        bin_counts = []\n","\n","        for i in range(len(conf_bins)-1):\n","            mask = (X >= conf_bins[i]) & (X < conf_bins[i+1])\n","            bin_data = y[mask]\n","            if len(bin_data) >= min_bin_number:\n","                bin_centers.append((conf_bins[i] + conf_bins[i+1]) / 2)\n","                bin_rates.append(bin_data.mean())\n","                bin_counts.append(len(bin_data))\n","\n","        bin_centers = np.array(bin_centers)\n","        bin_rates = np.array(bin_rates)\n","        bin_counts = np.array(bin_counts)\n","\n","        weights = np.sqrt(bin_counts)\n","\n","        results = {\n","            'accuracy': accuracy,\n","            'n_bins': len(bin_centers),\n","            'bin_centers': bin_centers,\n","            'bin_rates': bin_rates,\n","            'bin_sizes': bin_counts\n","        }\n","\n","\n","        try:\n","            linear_params, _ = curve_fit(linear_func, bin_centers, bin_rates,\n","                                        p0=[0, 0.5], sigma=1/weights)\n","\n","            results['linear_params'] = linear_params\n","            if show_summary:\n","                print(f\"  Linear fit successful: slope={linear_params[0]:.3f}, intercept={linear_params[1]:.3f}\")\n","\n","        except Exception as e:\n","            if show_summary:\n","                print(f\"  Linear fitting failed: {e}\")\n","            results['linear_params'] = None\n","\n","        nothing_hidden_results.append(results)\n","\n","\n","    if show_summary:\n","        print(\"\\n\\nCreating comparison plot...\")\n","\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n","    plt.rcParams.update({'font.size': font_size})\n","\n","\n","    ax1.set_title('Answer Hidden Opposite Advice', fontsize=font_size + 2)\n","\n","    for i, result in enumerate(model_results):\n","        if result.get('sigmoid_params') is not None:\n","            accuracy = result['accuracy']\n","\n","\n","            data_subset = opposite_hidden[opposite_hidden['other_llm_accuracy'] == accuracy]\n","            X_min = data_subset['initial_confidence_chosen'].min()\n","            X_max = data_subset['initial_confidence_chosen'].max()\n","            X_smooth = np.linspace(X_min, X_max, 200)\n","\n","\n","            sigmoid_curve = sigmoid_func_constrained(X_smooth, *result['sigmoid_params'])\n","            ax1.plot(X_smooth, sigmoid_curve, color=curve_colors[i], linewidth=5,\n","                    label=f\"{accuracy}% Accuracy\", alpha=0.9)\n","\n","\n","            bin_centers = result['bin_centers']\n","            bin_rates = result['bin_rates']\n","            bin_sizes = result['bin_sizes']\n","\n","            if len(bin_centers) > 0:\n","                max_size = max(bin_sizes)\n","                min_size = min(bin_sizes)\n","                sizes = [50 + 450 * (s - min_size) / (max_size - min_size) if max_size > min_size else 200\n","                         for s in bin_sizes]\n","\n","                ax1.scatter(bin_centers, bin_rates, color=curve_colors[i], s=sizes,\n","                           alpha=0.7, edgecolor='white', linewidth=1, zorder=5)\n","\n","\n","            a, b, c = result['sigmoid_params']\n","            if a > 0.5 and b != 0:\n","                conf_at_half = c - np.log(a/0.5 - 1)/b\n","                if 0 <= conf_at_half <= 1:\n","                    ax1.axvline(x=conf_at_half, color=curve_colors[i], linestyle='--',\n","                               linewidth=2, alpha=0.7)\n","\n","    ax2.set_title('Answer Hidden Neutral Advice', fontsize=font_size + 2)\n","\n","    for i, result in enumerate(nothing_hidden_results):\n","        if result.get('linear_params') is not None:\n","            accuracy = result['accuracy']\n","\n","\n","            data_subset = nothing_hidden[nothing_hidden['other_llm_accuracy'] == accuracy]\n","            X_min = data_subset['initial_confidence_chosen'].min()\n","            X_max = data_subset['initial_confidence_chosen'].max()\n","            X_smooth = np.linspace(X_min, X_max, 200)\n","\n","\n","            linear_curve = linear_func(X_smooth, *result['linear_params'])\n","            ax2.plot(X_smooth, linear_curve, color=curve_colors[i], linewidth=5,\n","                    label=f\"{accuracy}% Accuracy\", alpha=0.9)\n","\n","\n","            bin_centers = result['bin_centers']\n","            bin_rates = result['bin_rates']\n","            bin_sizes = result['bin_sizes']\n","\n","            if len(bin_centers) > 0:\n","                max_size = max(bin_sizes)\n","                min_size = min(bin_sizes)\n","                sizes = [50 + 450 * (s - min_size) / (max_size - min_size) if max_size > min_size else 200\n","                         for s in bin_sizes]\n","\n","                ax2.scatter(bin_centers, bin_rates, color=curve_colors[i], s=sizes,\n","                           alpha=0.7, edgecolor='white', linewidth=1, zorder=5)\n","\n","\n","            slope, intercept = result['linear_params']\n","            if slope != 0:\n","                conf_at_half = (0.5 - intercept) / slope\n","                if 0 <= conf_at_half <= 1:\n","                    ax2.axvline(x=conf_at_half, color=curve_colors[i], linestyle='--',\n","                               linewidth=2, alpha=0.7)\n","\n","    for ax in [ax1, ax2]:\n","        ax.axhline(y=0.5, color='gray', linestyle=':', alpha=0.5, linewidth=2)\n","\n","        ax.set_xlabel('Initial Confidence in Chosen Option', fontsize=font_size)\n","        ax.set_ylabel('Change of Mind Rate', fontsize=font_size)\n","        ax.legend(fontsize=font_size - 2)\n","        ax.set_ylim(0, 1.1)\n","        ax.set_xlim(0, 1)\n","\n","        ax.set_yticks([0, 0.25, 0.5, 0.75, 1])\n","        ax.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n","\n","        ax.spines['bottom'].set_linewidth(2)\n","        ax.spines['left'].set_linewidth(2)\n","        ax.spines['top'].set_visible(False)\n","        ax.spines['right'].set_visible(False)\n","        ax.tick_params(width=2)\n","\n","    plt.tight_layout()\n","\n","\n","    if save_figure:\n","        if save_path:\n","            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n","        else:\n","            plt.savefig(filename, dpi=300, bbox_inches='tight')\n","\n","    plt.show()\n","\n","\n","    if show_summary:\n","        print(\"\\n\\nSUMMARY\")\n","        print(\"=\"*60)\n","        print(f\"Opposite Hidden - Successfully fitted: {sum(1 for r in model_results if r.get('sigmoid_params') is not None)} curves\")\n","        print(f\"Nothing Hidden - Successfully fitted: {sum(1 for r in nothing_hidden_results if r.get('linear_params') is not None)} curves\")\n","\n","\n","        for accuracy in focus_accuracies:\n","            opp_count = len(opposite_hidden[opposite_hidden['other_llm_accuracy'] == accuracy])\n","            noth_count = len(nothing_hidden[nothing_hidden['other_llm_accuracy'] == accuracy])\n","            print(f\"\\n{accuracy}% accuracy data counts:\")\n","            print(f\"  Opposite Hidden: {opp_count} samples\")\n","            print(f\"  Nothing Hidden: {noth_count} samples\")\n","\n","    return fig, (ax1, ax2), model_results, nothing_hidden_results"],"metadata":{"id":"kkcbWtigVggP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_observed_vs_bayes_optimal_confidence(df,\n","                                             display_types=None,\n","                                             conditions=None,\n","                                             colors=None,\n","                                             bin_width=0.05,\n","                                             min_marker_size=10,\n","                                             max_marker_size=400,\n","                                             figsize_per_subplot=(6, 5),\n","                                             save_figure=False,\n","                                             save_path=None,\n","                                             filename='observed_final_confidence_composite_global_marker.png',\n","                                             dpi=300,\n","                                             show_diagonal=True,\n","                                             replace_nothing_with_neutral=True):\n","\n","    if display_types is None:\n","        display_types = ['hidden', 'shown']\n","\n","    if conditions is None:\n","        conditions = ['Nothing', 'Same', 'Opposite']\n","\n","    if colors is None:\n","        colors = ['tab:blue', 'tab:orange', 'tab:green']\n","\n","    bins = np.arange(0, 1 + bin_width, bin_width)\n","    bin_midpoints = bins[:-1] + bin_width/2\n","\n","    # Calculate global min/max for marker sizing across all data\n","    global_counts = []\n","    for condition in conditions:\n","        for disp in display_types:\n","            sub_df = df.loc[\n","                (df['initial_answer_display'] == disp) &\n","                (df['other_llm_answer_type'] == condition)\n","            ].copy()\n","            bayes_col = 'bayes_optimal_probability_initial_chosen'\n","            sub_df['bayes_bin'] = pd.cut(sub_df[bayes_col], bins, include_lowest=True, labels=bin_midpoints)\n","            counts = sub_df['bayes_bin'].value_counts().reindex(bin_midpoints, fill_value=0)\n","            global_counts.extend(counts.values)\n","\n","    global_min_count = np.min(global_counts) if global_counts else 0\n","    global_max_count = np.max(global_counts) if global_counts else 1\n","\n","    fig, axes = plt.subplots(1, len(conditions),\n","                            figsize=(figsize_per_subplot[0] * len(conditions), figsize_per_subplot[1]))\n","\n","    if len(conditions) == 1:\n","        axes = [axes]\n","\n","    for j, condition in enumerate(conditions):\n","        ax = axes[j]\n","\n","        for i, disp in enumerate(display_types):\n","            sub_df = df.loc[\n","                (df['initial_answer_display'] == disp) &\n","                (df['other_llm_answer_type'] == condition)\n","            ].copy()\n","\n","            bayes_col = 'bayes_optimal_probability_initial_chosen'\n","            conf_col = 'second_turn_confidence_initial_chosen'\n","            label = disp.capitalize()\n","\n","            sub_df['bayes_bin'] = pd.cut(sub_df[bayes_col], bins, include_lowest=True, labels=bin_midpoints)\n","\n","            mean_conf = sub_df.groupby('bayes_bin', observed=True)[conf_col].mean()\n","            counts = sub_df['bayes_bin'].value_counts().reindex(bin_midpoints, fill_value=0)\n","\n","            mean_full = pd.Series(index=bin_midpoints, data=np.nan, dtype=float)\n","            mean_full.loc[mean_conf.index.astype(float)] = mean_conf.values\n","\n","            # Global normalization of marker size\n","            if global_max_count > global_min_count:\n","                norm_counts = (counts - global_min_count) / (global_max_count - global_min_count)\n","            else:\n","                norm_counts = pd.Series(0.5, index=counts.index)\n","\n","            sizes = min_marker_size + norm_counts * (max_marker_size - min_marker_size)\n","\n","            ax.scatter(bin_midpoints, mean_full.values, s=sizes,\n","                      color=colors[i], label=label, edgecolor='black', alpha=0.7)\n","            ax.plot(bin_midpoints, mean_full.values, linestyle='-', color=colors[i])\n","\n","\n","        if show_diagonal:\n","            ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n","\n","        ax.set_xticks(np.arange(0, 1.1, 0.2))\n","        ax.set_yticks(np.arange(0, 1.1, 0.2))\n","        ax.set_xlabel('Bayes-optimal Probability')\n","        ax.set_xlim(0, 1.05)\n","        ax.set_ylim(0, 1.05)\n","\n","        condition_label = condition\n","        if replace_nothing_with_neutral and condition == 'Nothing':\n","            condition_label = 'Neutral'\n","        ax.set_title(f'{condition_label} Advice')\n","\n","        if j == 0:\n","            ax.set_ylabel('Observed Final Confidence')\n","            ax.legend(title='Answer')\n","        else:\n","            ax.set_ylabel('')\n","\n","        sns.despine(ax=ax)\n","\n","    plt.tight_layout()\n","\n","    if save_figure and save_path:\n","        os.makedirs(save_path, exist_ok=True)\n","        fig.savefig(os.path.join(save_path, filename), dpi=dpi)\n","\n","    plt.show()\n","\n","    return fig, axes"],"metadata":{"id":"ue3fl7Q7XP0P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_observed_vs_bayes_optimal_log_odds(df,\n","                                           x_limits=(-4, 4.75),\n","                                           y_limits=(-4, 4.75),\n","                                           display_types=None,\n","                                           conditions=None,\n","                                           colors=None,\n","                                           log_odds_bins=None,\n","                                           min_marker_size=10,\n","                                           max_marker_size=400,\n","                                           figsize_per_subplot=(6, 5),\n","                                           save_figure=False,\n","                                           save_path=None,\n","                                           filename='LogOdds_observed_final_log_odds_composite_global_marker.png',\n","                                           dpi=300,\n","                                           show_diagonal=True,\n","                                           show_grid=False,\n","                                           major_tick_spacing=2,\n","                                           minor_tick_spacing=1,\n","                                           replace_nothing_with_neutral=True,\n","                                           print_statistics=False):\n","\n","    if display_types is None:\n","        display_types = ['hidden', 'shown']\n","\n","    if conditions is None:\n","        conditions = ['Nothing', 'Same', 'Opposite']\n","\n","    if colors is None:\n","        colors = ['tab:blue', 'tab:orange', 'tab:green']\n","\n","    if log_odds_bins is None:\n","        log_odds_bins = np.linspace(-3, 3, 13)\n","\n","    log_odds_bin_midpoints = log_odds_bins[:-1] + np.diff(log_odds_bins)/2\n","\n","    if print_statistics:\n","        print(f\"Using axis limits - X: {x_limits}, Y: {y_limits}\")\n","        print(f\"X-axis range: {x_limits[1] - x_limits[0]:.1f}\")\n","        print(f\"Y-axis range: {y_limits[1] - y_limits[0]:.1f}\")\n","\n","    # Calculate global min/max for marker sizing across all data\n","    global_counts = []\n","    for condition in conditions:\n","        for disp in display_types:\n","            sub_df = df.loc[\n","                (df['initial_answer_display'] == disp) &\n","                (df['other_llm_answer_type'] == condition)\n","            ].copy()\n","\n","            bayes_col = 'bayes_optimal_log_odds_initial_chosen'\n","            sub_df['bayes_log_odds_bin'] = pd.cut(sub_df[bayes_col], log_odds_bins,\n","                                                   include_lowest=True, labels=log_odds_bin_midpoints)\n","            counts = sub_df['bayes_log_odds_bin'].value_counts().reindex(log_odds_bin_midpoints, fill_value=0)\n","            global_counts.extend(counts.values)\n","\n","    global_min_count = np.min(global_counts) if global_counts else 0\n","    global_max_count = np.max(global_counts) if global_counts else 1\n","\n","    fig, axes = plt.subplots(1, len(conditions),\n","                            figsize=(figsize_per_subplot[0] * len(conditions), figsize_per_subplot[1]))\n","\n","\n","    if len(conditions) == 1:\n","        axes = [axes]\n","\n","    for j, condition in enumerate(conditions):\n","        ax = axes[j]\n","\n","        for i, disp in enumerate(display_types):\n","            sub_df = df.loc[\n","                (df['initial_answer_display'] == disp) &\n","                (df['other_llm_answer_type'] == condition)\n","            ].copy()\n","\n","            bayes_col = 'bayes_optimal_log_odds_initial_chosen'\n","            conf_col = 'second_turn_confidence_initial_chosen_log_odds'\n","            label = disp.capitalize()\n","\n","            sub_df['bayes_log_odds_bin'] = pd.cut(sub_df[bayes_col], log_odds_bins,\n","                                                   include_lowest=True, labels=log_odds_bin_midpoints)\n","\n","\n","            mean_log_odds = sub_df.groupby('bayes_log_odds_bin', observed=True)[conf_col].mean()\n","            counts = sub_df['bayes_log_odds_bin'].value_counts().reindex(log_odds_bin_midpoints, fill_value=0)\n","\n","            mean_full = pd.Series(index=log_odds_bin_midpoints, data=np.nan, dtype=float)\n","            mean_full.loc[mean_log_odds.index.astype(float)] = mean_log_odds.values\n","\n","            # Global normalization of marker size\n","            if global_max_count > global_min_count:\n","                norm_counts = (counts - global_min_count) / (global_max_count - global_min_count)\n","            else:\n","                norm_counts = pd.Series(0.5, index=counts.index)\n","\n","            sizes = min_marker_size + norm_counts * (max_marker_size - min_marker_size)\n","\n","            ax.scatter(log_odds_bin_midpoints, mean_full.values, s=sizes, color=colors[i],\n","                       label=label, edgecolor='black', alpha=0.7)\n","            ax.plot(log_odds_bin_midpoints, mean_full.values, linestyle='-', color=colors[i])\n","\n","        if show_diagonal:\n","            diag_min = max(x_limits[0], y_limits[0])\n","            diag_max = min(x_limits[1], y_limits[1])\n","            ax.plot([diag_min, diag_max], [diag_min, diag_max], linestyle='--', color='gray')\n","\n","        ax.set_xlim(x_limits)\n","        ax.set_ylim(y_limits)\n","\n","        if x_limits == y_limits:\n","            ax.set_aspect('equal', adjustable='box')\n","\n","        major_x_ticks = np.arange(-10, 10, major_tick_spacing)\n","        major_y_ticks = np.arange(-10, 10, major_tick_spacing)\n","\n","\n","        minor_x_ticks = np.arange(-10, 10, minor_tick_spacing)\n","        minor_y_ticks = np.arange(-10, 10, minor_tick_spacing)\n","\n","        major_x_ticks = major_x_ticks[(major_x_ticks >= x_limits[0]) & (major_x_ticks <= x_limits[1])]\n","        major_y_ticks = major_y_ticks[(major_y_ticks >= y_limits[0]) & (major_y_ticks <= y_limits[1])]\n","        minor_x_ticks = minor_x_ticks[(minor_x_ticks >= x_limits[0]) & (minor_x_ticks <= x_limits[1])]\n","        minor_y_ticks = minor_y_ticks[(minor_y_ticks >= y_limits[0]) & (minor_y_ticks <= y_limits[1])]\n","\n","\n","        ax.set_xticks(major_x_ticks)\n","        ax.set_yticks(major_y_ticks)\n","        ax.set_xticks(minor_x_ticks, minor=True)\n","        ax.set_yticks(minor_y_ticks, minor=True)\n","\n","\n","        ax.tick_params(axis='both', which='major', labelsize=14, length=6, width=1.5)\n","        ax.tick_params(axis='both', which='minor', length=3, width=1)\n","\n","        ax.set_xlabel('Bayes-optimal Log Odds')\n","\n","\n","        if show_grid:\n","            ax.grid(True, alpha=0.3)\n","\n","        condition_label = condition\n","        if replace_nothing_with_neutral and condition == 'Nothing':\n","            condition_label = 'Neutral'\n","        ax.set_title(f'{condition_label} Advice')\n","\n","        if j == 0:\n","            ax.set_ylabel('Observed Final Log Odds')\n","            ax.legend(title='Answer')\n","        else:\n","            ax.set_ylabel('')\n","\n","        sns.despine(ax=ax)\n","\n","    plt.tight_layout()\n","\n","    if save_figure and save_path:\n","        os.makedirs(save_path, exist_ok=True)\n","        fig.savefig(os.path.join(save_path, filename), dpi=dpi)\n","\n","    plt.show()\n","\n","\n","    if print_statistics:\n","        all_x_values = []\n","        all_y_values = []\n","\n","        for condition in conditions:\n","            for disp in display_types:\n","                sub_df = df.loc[\n","                    (df['initial_answer_display'] == disp) &\n","                    (df['other_llm_answer_type'] == condition)\n","                ].copy()\n","\n","                if len(sub_df) > 0:\n","                    bayes_col = 'bayes_optimal_log_odds_initial_chosen'\n","                    conf_col = 'second_turn_confidence_initial_chosen_log_odds'\n","\n","\n","                    all_x_values.extend(sub_df[bayes_col].dropna().values)\n","\n","                    all_y_values.extend(sub_df[conf_col].dropna().values)\n","\n","        if all_x_values and all_y_values:\n","\n","            print(f\"\\nData coverage statistics:\")\n","            print(f\"X-axis (Bayes optimal): min={np.min(all_x_values):.2f}, max={np.max(all_x_values):.2f}\")\n","            print(f\"Y-axis (Observed): min={np.min(all_y_values):.2f}, max={np.max(all_y_values):.2f}\")\n","\n","            x_captured = np.sum((np.array(all_x_values) >= x_limits[0]) & (np.array(all_x_values) <= x_limits[1]))\n","            y_captured = np.sum((np.array(all_y_values) >= y_limits[0]) & (np.array(all_y_values) <= y_limits[1]))\n","            x_percentage = (x_captured / len(all_x_values)) * 100\n","            y_percentage = (y_captured / len(all_y_values)) * 100\n","\n","            print(f\"\\nPercentage of data captured by axis limits:\")\n","            print(f\"  X-axis {x_limits}: {x_percentage:.1f}% ({x_captured}/{len(all_x_values)} points)\")\n","            print(f\"  Y-axis {y_limits}: {y_percentage:.1f}% ({y_captured}/{len(all_y_values)} points)\")\n","            print(f\"  Points outside limits: X={len(all_x_values) - x_captured}, Y={len(all_y_values) - y_captured}\")\n","\n","    return fig, axes"],"metadata":{"id":"VTITJ9wQXx5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_bayes_confidence_update_comparison(df,\n","                                           condition='Opposite',\n","                                           accuracy=80,\n","                                           display_type='hidden',\n","                                           bin_width=0.1,\n","                                           figsize=(10, 6),\n","                                           save_figure=False,\n","                                           save_path=None,\n","                                           filename=None,\n","                                           dpi=300,\n","                                           show_legend=True,\n","                                           ylabel='Confidence Change',\n","                                           xlabel='Initial Confidence'):\n","\n","\n","    bins = np.arange(0, 1 + bin_width, bin_width)\n","    bin_labels = [f'{b:.1f}' if b in np.arange(0, 1.1, 0.2) else '' for b in bins[:-1]]\n","\n","    sub_df = df[\n","        (df['initial_answer_display'] == display_type) &\n","        (df['other_llm_answer_type'] == condition) &\n","        (df['other_llm_accuracy'] == accuracy)\n","    ].copy()\n","\n","    if len(sub_df) == 0:\n","        print(f\"No data found for {display_type} display, {condition} condition, {accuracy}% accuracy\")\n","        return None, None\n","\n","    if display_type == 'hog':\n","        sub_df['initial_confidence'] = sub_df['initial_confidence_hog_chosen']\n","        sub_df['bayes_optimal_prob'] = sub_df['bayes_optimal_probability_hog_chosen']\n","        sub_df['confidence_gap'] = sub_df['confidence_gap_hog_chosen']\n","    else:\n","        sub_df['initial_confidence'] = sub_df['initial_confidence_chosen']\n","        sub_df['bayes_optimal_prob'] = sub_df['bayes_optimal_probability_initial_chosen']\n","        sub_df['confidence_gap'] = sub_df['confidence_gap_initial_chosen']\n","\n","    sub_df['bayes_update'] = sub_df['bayes_optimal_prob'] - sub_df['initial_confidence']\n","    sub_df['confidence_bin'] = pd.cut(sub_df['initial_confidence'], bins=bins, include_lowest=True)\n","\n","\n","    sub_df_melted = sub_df.melt(id_vars='confidence_bin',\n","                                value_vars=['bayes_update', 'confidence_gap'],\n","                                var_name='Measure',\n","                                value_name='Value')\n","\n","    measure_names = {\n","        'bayes_update': 'Bayesian Update',\n","        'confidence_gap': 'Observed Update'\n","    }\n","    sub_df_melted['Measure'] = sub_df_melted['Measure'].map(measure_names)\n","\n","    fig, ax = plt.subplots(figsize=figsize)\n","    sns.boxplot(x='confidence_bin', y='Value', hue='Measure', data=sub_df_melted, ax=ax)\n","    ax.set_xticks(np.arange(len(bins)-1))\n","    ax.set_xticklabels(bin_labels, rotation=0, fontsize=14)\n","    ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n","\n","    ax.set_xlabel(xlabel, fontsize=16)\n","    ax.set_ylabel(ylabel, fontsize=16)\n","    ax.tick_params(axis='x', labelsize=14)\n","    ax.tick_params(axis='y', labelsize=14)\n","    ax.set_title(f'{display_type.capitalize()} Display - {condition} Advice - {accuracy}% Accuracy',\n","                 fontsize=18, pad=15)\n","\n","    if show_legend:\n","        ax.legend(title='Measure', fontsize=14, title_fontsize=16)\n","    else:\n","        ax.legend().remove()\n","\n","    sns.despine()\n","\n","    plt.tight_layout()\n","    if save_figure:\n","        if save_path:\n","            plt.savefig(save_path, dpi=dpi)\n","        elif filename:\n","            plt.savefig(filename, dpi=dpi)\n","        else:\n","\n","            auto_filename = f'bayes_confidence_update_{condition.lower()}{display_type}{accuracy}.png'\n","            plt.savefig(auto_filename, dpi=dpi)\n","\n","    plt.show()\n","\n","    return fig, ax"],"metadata":{"id":"hNWqvA6CZX1-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_bayes_update_grid_all_accuracies(df,\n","                                         condition='Opposite',\n","                                         display_type='hidden',\n","                                         bin_width=0.1,\n","                                         figsize=(16, 18),\n","                                         save_figure=False,\n","                                         save_path=None,\n","                                         filename=None,\n","                                         dpi=300,\n","                                         y_range=(-1, 0.2),\n","                                         y_tick_spacing=0.2):\n","\n","    accuracies = sorted(df['other_llm_accuracy'].unique())\n","    bins = np.arange(0, 1 + bin_width, bin_width)\n","    bin_labels = [f'{b:.1f}' if b in np.arange(0, 1.1, 0.2) else '' for b in bins[:-1]]\n","\n","    n_accuracies = len(accuracies)\n","    n_cols = 2\n","    n_rows = int(np.ceil(n_accuracies / n_cols))\n","    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n","    axes = axes.flatten()\n","\n","    handles, labels = None, None\n","\n","    for i, (ax, selected_accuracy) in enumerate(zip(axes[:n_accuracies], accuracies)):\n","        sub_df = df[\n","            (df['initial_answer_display'] == display_type) &\n","            (df['other_llm_answer_type'] == condition) &\n","            (df['other_llm_accuracy'] == selected_accuracy)\n","        ].copy()\n","\n","        if len(sub_df) == 0:\n","            ax.text(0.5, 0.5, f'No data for\\n{selected_accuracy}% accuracy',\n","                    ha='center', va='center', transform=ax.transAxes)\n","            ax.set_xticks([])\n","            ax.set_yticks([])\n","            continue\n","        if display_type == 'hog':\n","            sub_df['initial_confidence'] = sub_df['initial_confidence_hog_chosen']\n","            sub_df['bayes_optimal_prob'] = sub_df['bayes_optimal_probability_hog_chosen']\n","            sub_df['confidence_gap'] = sub_df['confidence_gap_hog_chosen']\n","        else:\n","            sub_df['initial_confidence'] = sub_df['initial_confidence_chosen']\n","            sub_df['bayes_optimal_prob'] = sub_df['bayes_optimal_probability_initial_chosen']\n","            sub_df['confidence_gap'] = sub_df['confidence_gap_initial_chosen']\n","\n","        sub_df['bayes_update'] = sub_df['bayes_optimal_prob'] - sub_df['initial_confidence']\n","        sub_df['confidence_bin'] = pd.cut(sub_df['initial_confidence'], bins=bins, include_lowest=True)\n","\n","        sub_df_melted = sub_df.melt(id_vars='confidence_bin',\n","                                    value_vars=['bayes_update', 'confidence_gap'],\n","                                    var_name='Measure',\n","                                    value_name='Value')\n","\n","        measure_names = {\n","            'bayes_update': 'Bayesian Update',\n","            'confidence_gap': 'Observed Update'\n","        }\n","        sub_df_melted['Measure'] = sub_df_melted['Measure'].map(measure_names)\n","        sns.boxplot(x='confidence_bin', y='Value', hue='Measure', data=sub_df_melted, ax=ax)\n","        ax.axhline(0, linestyle=':', color='gray')\n","\n","        ax.spines['bottom'].set_linewidth(2)\n","        ax.spines['left'].set_linewidth(2)\n","        ax.spines['bottom'].set_color('black')\n","        ax.spines['left'].set_color('black')\n","\n","        ax.tick_params(axis='both', which='major', width=2, length=7, labelsize=14, colors='black')\n","        ax.set_xlabel('Initial Confidence', fontsize=16)\n","        ax.set_ylabel('Confidence Change', fontsize=16)\n","\n","        ax.set_xticks(np.arange(len(bin_labels)))\n","        ax.set_xticklabels(bin_labels, fontsize=14)\n","\n","        y_ticks = np.arange(y_range[0], y_range[1] + y_tick_spacing, y_tick_spacing)\n","        ax.set_yticks(y_ticks)\n","        ax.set_yticklabels([f'{tick:.1f}' for tick in y_ticks], fontsize=14)\n","        ax.set_ylim(y_range[0] - 0.05, y_range[1] + 0.05)\n","\n","        ax.grid(False)\n","\n","        if handles is None:\n","            handles, labels = ax.get_legend_handles_labels()\n","\n","        ax.legend().remove()\n","\n","        ax.set_title(f'Accuracy = {selected_accuracy}%', fontsize=16)\n","\n","    for j in range(n_accuracies, len(axes)):\n","        axes[j].set_visible(False)\n","\n","    sns.despine()\n","    fig.legend(handles, labels, loc='upper right', fontsize=14, title='Measure', title_fontsize=16)\n","\n","    main_title = f'{display_type.capitalize()} Display - {condition} Advice'\n","    fig.suptitle(main_title, fontsize=20, y=0.995)\n","\n","    plt.tight_layout(rect=[0, 0, 0.9, 0.99])\n","\n","    if save_figure:\n","        if save_path:\n","            plt.savefig(save_path, dpi=dpi)\n","        elif filename:\n","            plt.savefig(filename, dpi=dpi)\n","        else:\n","\n","            auto_filename = f'bayes_update_grid_{condition.lower()}_{display_type}_all_accuracies.png'\n","            plt.savefig(auto_filename, dpi=dpi)\n","\n","    plt.show()\n","\n","    return fig, axes"],"metadata":{"id":"U4Uts1ATZt7C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_answer_wrong_COM_composite(df,\n","                                   available_display_types=None,\n","                                   conditions=None,\n","                                   accuracies=None,\n","                                   colors=None,\n","                                   figsize_per_condition=(8, 6),\n","                                   save_figure=False,\n","                                   save_path=None,\n","                                   filename='Answer_Wrong_COM_Composite.png',\n","                                   dpi=300,\n","                                   ylabel='Change of Initial Answer Rate (%)',\n","                                   hog_label='Wrong',\n","                                   bar_width=0.35,\n","                                   ylim=(-5, 105)):\n","\n","    if colors is None:\n","        colors = {'shown': 'tab:orange', 'hidden': 'tab:blue', 'hog': 'tab:green'}\n","\n","    if available_display_types is None:\n","        available_display_types = ['shown', 'hog']\n","\n","    if conditions is None:\n","        conditions = df['other_llm_answer_type'].unique()\n","\n","    if accuracies is None:\n","        accuracies = sorted(df['other_llm_accuracy'].unique())\n","\n","    fig, axes = plt.subplots(1, len(conditions),\n","                            figsize=(figsize_per_condition[0] * len(conditions), figsize_per_condition[1]),\n","                            squeeze=False)\n","\n","    for j, condition in enumerate(conditions):\n","        ax = axes[0, j]\n","\n","        x = np.arange(len(accuracies))\n","\n","        for idx, display_type in enumerate(available_display_types):\n","            sub_df = df[\n","                (df['initial_answer_display'] == display_type) &\n","                (df['other_llm_answer_type'] == condition)\n","            ]\n","\n","            change_col = 'change_of_mind_hog' if display_type == 'hog' else 'change_of_mind'\n","            if display_type == 'hog':\n","                label = hog_label\n","            else:\n","                label = display_type.capitalize()\n","\n","            means = sub_df.groupby('other_llm_accuracy')[change_col].mean() * 100\n","            sems = sub_df.groupby('other_llm_accuracy')[change_col].sem() * 100\n","\n","            means = means.reindex(accuracies, fill_value=np.nan)\n","            sems = sems.reindex(accuracies, fill_value=0)\n","\n","            ax.bar(\n","                x + idx * bar_width,\n","                means,\n","                bar_width,\n","                yerr=sems,\n","                capsize=5,\n","                label=label,\n","                color=colors[display_type],\n","                alpha=0.8,\n","                edgecolor='black'\n","            )\n","\n","        display_condition = 'Neutral' if condition == 'Nothing' else condition\n","        ax.set_title(f'{display_condition} Advice')\n","\n","        ax.set_xlabel('LLM Accuracy (%)')\n","        ax.set_ylabel(ylabel)\n","        ax.set_xticks(x + bar_width / 2)\n","        ax.set_xticklabels(accuracies)\n","        ax.set_ylim(ylim[0], ylim[1])\n","        ax.spines['top'].set_visible(False)\n","        ax.spines['right'].set_visible(False)\n","        ax.spines['bottom'].set_linewidth(1.2)\n","        ax.spines['left'].set_linewidth(1.2)\n","        ax.legend(title=\"Answer\")\n","\n","    plt.tight_layout()\n","\n","    if save_figure and save_path:\n","        os.makedirs(save_path, exist_ok=True)\n","        fig.savefig(os.path.join(save_path, filename), dpi=dpi)\n","\n","    plt.show()\n","\n","    return fig, axes"],"metadata":{"id":"K-uY5DbPcted"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_for_composite_CSB_COM_acrossmodels(df,\n","                                        figsize=(8, 6), dpi=300, ylim=(-5, 100)):\n","    sns.set(style=\"white\", context=\"talk\")\n","\n","    df = df.copy()\n","    df['initial_answer_display_norm'] = df['initial_answer_display'].astype(str).str.strip().str.lower()\n","    df['other_llm_answer_type_norm'] = df['other_llm_answer_type'].astype(str).str.strip().str.capitalize()\n","\n","    display_types = ['shown', 'hidden']\n","    display_labels = {'shown': 'Shown', 'hidden': 'Hidden'}\n","    conditions = ['Opposite', 'Same', 'Nothing']\n","\n","    means = {dt: [] for dt in display_types}\n","    sems  = {dt: [] for dt in display_types}\n","\n","    for cond in conditions:\n","        for dt in display_types:\n","            sub = df[\n","                (df['initial_answer_display_norm'] == dt) &\n","                (df['other_llm_answer_type_norm'] == cond)\n","            ]\n","\n","            vals = sub['change_of_mind'] * 100\n","            m = vals.mean() if len(vals) else np.nan\n","            se = vals.sem(ddof=1) if len(vals) > 1 else 0.0\n","            means[dt].append(m)\n","            sems[dt].append(se)\n","\n","\n","    fig, ax = plt.subplots(figsize=figsize)\n","    x = np.arange(len(conditions))\n","    bar_width = 0.35\n","\n","    ax.bar(x - bar_width/2, means['shown'], bar_width,\n","           yerr=sems['shown'], capsize=5, label=display_labels['shown'],\n","           edgecolor='black', linewidth=0.6, alpha=0.9, color='tab:orange')\n","\n","    ax.bar(x + bar_width/2, means['hidden'], bar_width,\n","           yerr=sems['hidden'], capsize=5, label=display_labels['hidden'],\n","           edgecolor='black', linewidth=0.6, alpha=0.9, color='tab:blue')\n","\n","    ax.set_xticks(x)\n","    ax.set_xticklabels(conditions)\n","    ax.set_xlabel('Advice Condition')\n","    ax.set_ylabel('Change of Mind (%)')\n","    ax.set_ylim(ylim)\n","    ax.legend(frameon=False, title='Initial Answer Visibility')\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['right'].set_visible(False)\n","\n","    plt.tight_layout()\n","\n","\n","    return fig, ax"],"metadata":{"id":"d6QammKTXlXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_for_composite_CSB_conf_acrossmodels(df, figsize=(8, 6), ylim=None):\n","\n","    sns.set(style=\"white\", context=\"talk\")\n","\n","\n","    df = df.copy()\n","    df['initial_answer_display_norm'] = df['initial_answer_display'].astype(str).str.strip().str.lower()\n","    df['other_llm_answer_type_norm'] = df['other_llm_answer_type'].astype(str).str.strip().str.capitalize()\n","\n","    display_types = ['shown', 'hidden']\n","    display_labels = {'shown': 'Shown', 'hidden': 'Hidden'}\n","    conditions = ['Opposite', 'Same', 'Nothing']\n","\n","\n","    df['confidence_change'] = df['second_turn_confidence_initial_chosen'] - df['initial_confidence_chosen']\n","\n","\n","    means = {dt: [] for dt in display_types}\n","    sems  = {dt: [] for dt in display_types}\n","\n","    for cond in conditions:\n","        for dt in display_types:\n","            sub = df[\n","                (df['initial_answer_display_norm'] == dt) &\n","                (df['other_llm_answer_type_norm'] == cond)\n","            ]\n","            vals = sub['confidence_change']\n","            m = vals.mean() if len(vals) else np.nan\n","            se = vals.sem(ddof=1) if len(vals) > 1 else 0.0\n","            means[dt].append(m)\n","            sems[dt].append(se)\n","\n","\n","    fig, ax = plt.subplots(figsize=figsize)\n","    x = np.arange(len(conditions))\n","    bar_width = 0.35\n","\n","    ax.bar(x - bar_width/2, means['shown'], bar_width,\n","           yerr=sems['shown'], capsize=5, label=display_labels['shown'],\n","           edgecolor='black', linewidth=0.6, alpha=0.9, color='tab:orange')\n","\n","    ax.bar(x + bar_width/2, means['hidden'], bar_width,\n","           yerr=sems['hidden'], capsize=5, label=display_labels['hidden'],\n","           edgecolor='black', linewidth=0.6, alpha=0.9, color='tab:blue')\n","\n","    ax.set_xticks(x)\n","\n","    condition_labels = ['Opposite', 'Same', 'Neutral']\n","    ax.set_xticklabels(condition_labels)\n","    ax.set_xlabel('Advice Condition')\n","    ax.set_ylabel('Confidence Change')\n","    ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n","\n","    if ylim is not None:\n","        ax.set_ylim(ylim)\n","\n","    ax.legend(frameon=False, title='Initial Answer Visibility')\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['right'].set_visible(False)\n","\n","    plt.tight_layout()\n","\n","    return fig, ax"],"metadata":{"id":"Peqs9EDZYdCJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_obs_bayes_pred_COM_allmodels(df, figsize=(8, 6), print_stats=False, ylim=(-5, 105)):\n","\n","    sns.set(style=\"white\", context=\"talk\")\n","\n","    def calculate_bayes_com(row):\n","        probs = [\n","            row['bayes_optimal_probability_1'],\n","            row['bayes_optimal_probability_2'],\n","            row['bayes_optimal_probability_3'],\n","            row['bayes_optimal_probability_4']\n","        ] if 'bayes_optimal_probability_1' in row else [\n","            row['bayes_optimal_probability_a'],\n","            row['bayes_optimal_probability_b']\n","        ]\n","\n","        initial_prob = row['bayes_optimal_probability_initial_chosen']\n","        max_prob = max(probs)\n","\n","        return int(initial_prob < max_prob - 1e-10)\n","\n","    df = df.copy()\n","    if 'bayes_com' not in df.columns:\n","        df['bayes_com'] = df.apply(calculate_bayes_com, axis=1)\n","\n","    colors = {'shown': 'tab:orange', 'hidden': 'tab:blue', 'hog': 'tab:gray'}\n","    available_display_types = [dt for dt in ['shown', 'hidden', 'hog']\n","                               if dt in df['initial_answer_display'].unique()]\n","    condition = 'Opposite'\n","    accuracies = sorted(df['other_llm_accuracy'].unique())\n","\n","\n","    fig, ax = plt.subplots(figsize=figsize)\n","\n","\n","    num_display_types = len(available_display_types)\n","    bar_width = 0.8 / (num_display_types * 2)\n","    x = np.arange(len(accuracies))\n","\n","    for idx, display_type in enumerate(available_display_types):\n","        sub_df = df[\n","            (df['initial_answer_display'] == display_type) &\n","            (df['other_llm_answer_type'] == condition)\n","        ]\n","\n","        change_col = 'change_of_mind_hog' if display_type == 'hog' else 'change_of_mind'\n","\n","        observed_means = []\n","        observed_sems = []\n","        bayes_means = []\n","        bayes_sems = []\n","\n","        for acc in accuracies:\n","            acc_data = sub_df[sub_df['other_llm_accuracy'] == acc]\n","            if len(acc_data) > 0:\n","                obs_mean = acc_data[change_col].mean() * 100\n","                obs_sem = acc_data[change_col].sem() * 100 if len(acc_data) > 1 else 0\n","                observed_means.append(obs_mean)\n","                observed_sems.append(obs_sem)\n","\n","                bayes_mean = acc_data['bayes_com'].mean() * 100\n","                bayes_sem = acc_data['bayes_com'].sem() * 100 if len(acc_data) > 1 else 0\n","                bayes_means.append(bayes_mean)\n","                bayes_sems.append(bayes_sem)\n","            else:\n","                observed_means.append(np.nan)\n","                observed_sems.append(0)\n","                bayes_means.append(np.nan)\n","                bayes_sems.append(0)\n","\n","        observed_means = np.array(observed_means)\n","        observed_sems = np.array(observed_sems)\n","        bayes_means = np.array(bayes_means)\n","        bayes_sems = np.array(bayes_sems)\n","\n","        bar_offset = (idx * 2) * bar_width - (num_display_types - 1) * bar_width\n","\n","\n","        ax.bar(\n","            x + bar_offset,\n","            observed_means,\n","            bar_width,\n","            yerr=observed_sems,\n","            capsize=5,\n","            label=f'{display_type.capitalize()} (Observed)',\n","            color=colors[display_type],\n","            alpha=0.8,\n","            edgecolor='black'\n","        )\n","\n","\n","        ax.bar(\n","            x + bar_offset + bar_width,\n","            bayes_means,\n","            bar_width,\n","            yerr=bayes_sems,\n","            capsize=5,\n","            label=f'{display_type.capitalize()} (Bayes Optimal)',\n","            color=colors[display_type],\n","            alpha=0.4,\n","            edgecolor='black',\n","            hatch='//'\n","        )\n","\n","    ax.set_xlabel('Advice Accuracy (%)')\n","    ax.set_ylabel('Change of Mind (%)')\n","    ax.set_xticks(x)\n","    ax.set_xticklabels(accuracies)\n","    ax.set_ylim(ylim)\n","\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['right'].set_visible(False)\n","    ax.spines['bottom'].set_linewidth(1.2)\n","    ax.spines['left'].set_linewidth(1.2)\n","\n","    ax.grid(axis='y', alpha=0.3, linestyle='--')\n","\n","    plt.tight_layout()\n","\n","\n","\n","    return fig, ax"],"metadata":{"id":"t2Na4FeeaORW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_obs_bayes_pred_confidence_allmodels(df, figsize=(8, 6), ylim=(-0.9, 0.3)):\n","\n","    sns.set(style=\"white\", context=\"talk\")\n","\n","\n","    df = df.copy()\n","    df['bayes_confidence_gap'] = df['bayes_optimal_probability_initial_chosen'] - df['initial_confidence_chosen']\n","\n","\n","    colors = {'shown': 'tab:orange', 'hidden': 'tab:blue', 'hog': 'tab:gray'}\n","    available_display_types = [dt for dt in ['shown', 'hidden', 'hog']\n","                               if dt in df['initial_answer_display'].unique()]\n","    condition = 'Opposite'\n","    accuracies = sorted(df['other_llm_accuracy'].unique())\n","\n","\n","    fig, ax = plt.subplots(figsize=figsize)\n","\n","\n","    num_display_types = len(available_display_types)\n","    bar_width = 0.8 / (num_display_types * 2)\n","    x = np.arange(len(accuracies))\n","\n","    for idx, display_type in enumerate(available_display_types):\n","        sub_df = df[\n","            (df['initial_answer_display'] == display_type) &\n","            (df['other_llm_answer_type'] == condition)\n","        ].copy()\n","\n","        sub_df['confidence_change'] = sub_df['second_turn_confidence_initial_chosen'] - sub_df['initial_confidence_chosen']\n","\n","\n","        observed_means = []\n","        observed_sems = []\n","        bayes_means = []\n","        bayes_sems = []\n","\n","        for acc in accuracies:\n","            acc_data = sub_df[sub_df['other_llm_accuracy'] == acc]\n","            if len(acc_data) > 0:\n","\n","                obs_mean = acc_data['confidence_change'].mean()\n","                obs_sem = acc_data['confidence_change'].sem() if len(acc_data) > 1 else 0\n","                observed_means.append(obs_mean)\n","                observed_sems.append(obs_sem)\n","\n","                bayes_mean = acc_data['bayes_confidence_gap'].mean()\n","                bayes_sem = acc_data['bayes_confidence_gap'].sem() if len(acc_data) > 1 else 0\n","                bayes_means.append(bayes_mean)\n","                bayes_sems.append(bayes_sem)\n","            else:\n","                observed_means.append(np.nan)\n","                observed_sems.append(0)\n","                bayes_means.append(np.nan)\n","                bayes_sems.append(0)\n","\n","        observed_means = np.array(observed_means)\n","        observed_sems = np.array(observed_sems)\n","        bayes_means = np.array(bayes_means)\n","        bayes_sems = np.array(bayes_sems)\n","\n","\n","        bar_offset = (idx * 2) * bar_width - (num_display_types - 1) * bar_width\n","\n","\n","        ax.bar(\n","            x + bar_offset,\n","            observed_means,\n","            bar_width,\n","            yerr=observed_sems,\n","            capsize=5,\n","            label=f'{display_type.capitalize()} (Observed)',\n","            color=colors[display_type],\n","            alpha=0.8,\n","            edgecolor='black'\n","        )\n","\n","\n","        ax.bar(\n","            x + bar_offset + bar_width,\n","            bayes_means,\n","            bar_width,\n","            yerr=bayes_sems,\n","            capsize=5,\n","            label=f'{display_type.capitalize()} (Bayes Optimal)',\n","            color=colors[display_type],\n","            alpha=0.4,\n","            edgecolor='black',\n","            hatch='//'\n","        )\n","\n","    ax.set_xlabel('Advice Accuracy (%)')\n","    ax.set_ylabel('Confidence Gap')\n","    ax.set_xticks(x)\n","    ax.set_xticklabels(accuracies)\n","    ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n","    ax.set_ylim(ylim)\n","\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['right'].set_visible(False)\n","    ax.spines['bottom'].set_linewidth(1.2)\n","    ax.spines['left'].set_linewidth(1.2)\n","\n","    ax.grid(axis='y', alpha=0.3, linestyle='--')\n","\n","    plt.tight_layout()\n","\n","    return fig, ax"],"metadata":{"id":"thyMuo4fbh3s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Function: Over/Underconfidence Score (OUCS)"],"metadata":{"id":"AI4HE03EtEpX"}},{"cell_type":"code","source":["def calc_overunderconfidence_score(df,\n","                                  second_choice_var=\"initial\",\n","                                  expt_type=None,\n","                                  collapse_accuracy=True,\n","                                  split_by_initial_correctness=False,\n","                                  split_by_change_of_mind=False,\n","                                  split_by_change_of_mind_hog=False,\n","                                  bins=None):\n","\n","    if 'change_of_mind' not in df.columns:\n","        df['change_of_mind'] = (df['initial_answer'] != df['final_answer']).astype(int)\n","\n","    if expt_type == \"hog\" and 'change_of_mind_hog' not in df.columns:\n","        df['change_of_mind_hog'] = (df['final_answer'] != df['initial_answer_hog']).astype(int)\n","\n","    if bins is None:\n","        bins = np.arange(0, 1.05, 0.05)\n","    bin_midpoints = bins[:-1] + np.diff(bins)/2\n","\n","    def get_columns(display_type):\n","        if display_type == 'hog':\n","            return {\n","                'bayes': \"bayes_optimal_probability_hog_chosen\",\n","                'option': \"second_turn_confidence_hog_chosen\"\n","            }\n","        else:\n","            return {\n","                'bayes': f\"bayes_optimal_probability_{second_choice_var}_chosen\",\n","                'option': f\"second_turn_confidence_{second_choice_var}_chosen\"\n","            }\n","\n","    def calculate_score(binned_stats, bin_midpoints, total_count):\n","        score = 0\n","        for index, row in binned_stats.iterrows():\n","            avg_confidence = row['mean']\n","            bin_midpoint = bin_midpoints[index]\n","            bin_count = row['count']\n","            if not np.isnan(avg_confidence) and total_count > 0:\n","                weight = bin_count / total_count\n","                score += (avg_confidence - bin_midpoint) * weight\n","        return score\n","    display_types = ['hidden', 'shown']\n","    if split_by_change_of_mind_hog:\n","        display_types = ['hog']\n","\n","    answer_types = ['Nothing', 'Same', 'Opposite']\n","    results_list = []\n","\n","    if split_by_initial_correctness:\n","        split_col = 'initial_binary_correctness'\n","        split_values = [0, 1]\n","    elif split_by_change_of_mind:\n","        split_col = 'change_of_mind'\n","        split_values = [0, 1]\n","    elif split_by_change_of_mind_hog:\n","        split_col = 'change_of_mind_hog'\n","        split_values = [0, 1]\n","    else:\n","        split_col = None\n","        split_values = [None]\n","\n","    for split_value in split_values:\n","        for answer_type in answer_types:\n","            for display_type in display_types:\n","\n","                cols = get_columns(display_type)\n","                if split_col is not None:\n","                    subset_df = df[\n","                        (df['other_llm_answer_type'] == answer_type) &\n","                        (df['initial_answer_display'] == display_type) &\n","                        (df[split_col] == split_value)\n","                    ].copy()\n","                else:\n","                    subset_df = df[\n","                        (df['other_llm_answer_type'] == answer_type) &\n","                        (df['initial_answer_display'] == display_type)\n","                    ].copy()\n","\n","                if subset_df.empty:\n","                    continue\n","\n","                if len(subset_df) <= 1:\n","                    subset_df[cols['bayes']] = subset_df[cols['bayes']].fillna(0)\n","\n","\n","                subset_df['bayes_prob_bin'] = pd.cut(subset_df[cols['bayes']],\n","                                                     bins=bins,\n","                                                     include_lowest=True,\n","                                                     right=False)\n","                binned_stats = subset_df.groupby('bayes_prob_bin', observed=False)[cols['option']].agg(\n","                    ['mean', 'sem', 'count']\n","                ).reset_index()\n","                total_count = len(subset_df)\n","                score = calculate_score(binned_stats, bin_midpoints, total_count)\n","\n","                results_list.append({\n","                    'Answer Type': answer_type,\n","                    'Display Type': display_type,\n","                    'Score': round(score, 4)\n","                })\n","\n","    results_df = pd.DataFrame(results_list)\n","    print(results_df.to_string(index=False))\n","\n","    return results_df"],"metadata":{"id":"Xj2czbZzha7B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CODE TO CREATE FIGURES AND TABLES"],"metadata":{"id":"MKCFKakK_Jeg"}},{"cell_type":"markdown","source":["## Gemma 3 12B"],"metadata":{"id":"D37BDjgeIS-p"}},{"cell_type":"code","source":["expt_type = \"latitude\"\n","file_path = f\"{the_dir}gemma12b_latitude_experiment_data.csv\"\n","df = pd.read_csv(file_path) #"],"metadata":{"id":"XTwZTopUIJz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_no_nans = find_nan_in_df(df)\n","df = df_no_nans"],"metadata":{"id":"0EJu7icOL32T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = add_new_confidence_columns(df, expt_type)\n","df = add_new_confidence_columns_log_odds_space(df, expt_type)\n","df = add_bayes_optimal_columns(df)\n","df = add_bayes_optimal_columns_log_odds_space(df)"],"metadata":{"id":"3-vBnAAyMKJG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**FIGURE 2A**"],"metadata":{"id":"q69jNWda70oV"}},{"cell_type":"code","source":["fig, axes = plot_change_of_mind_by_condition(df)"],"metadata":{"id":"s7-6M8X8QRnn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**FIGURE 2B**"],"metadata":{"id":"EIfd7MUr77GL"}},{"cell_type":"code","source":["fig, axes = plot_confidence_change_by_condition(df)"],"metadata":{"id":"sXfySmQaMmQ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**FIGURE 9**"],"metadata":{"id":"hruzMimG7_WD"}},{"cell_type":"code","source":["fig, axes = plot_confidence_change_log_odds_by_condition(df)"],"metadata":{"id":"Tfotj7OgQx8T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**FIGURE 3**"],"metadata":{"id":"R33HIVWj8CVk"}},{"cell_type":"code","source":["fig, axes = plot_confidence_com_grid(df)"],"metadata":{"id":"6-ZcE7EAU07d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Figure 4**"],"metadata":{"id":"I9EvbQONXyZU"}},{"cell_type":"code","source":["fig, ax = plot_for_composite_CSB_COM_acrossmodels(df)\n","fig, ax = plot_for_composite_CSB_conf_acrossmodels(df)"],"metadata":{"id":"PVxxs3bSXxq-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Figure 5**"],"metadata":{"id":"OhRvLRrrYZlZ"}},{"cell_type":"code","source":["figs = plot_obs_bayes_pred_COM_allmodels(df)\n","fig, ax = plot_obs_bayes_pred_confidence_allmodels(df)"],"metadata":{"id":"xD6w6-oBYY0A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 1**"],"metadata":{"id":"V623NFfC8Ed_"}},{"cell_type":"code","source":["fig, axes, sigmoid_results, linear_results = plot_non_linear_threshold_OH_NH_COM_conf(df)"],"metadata":{"id":"6uLK-0YlVkrC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**FIGURE 2C**"],"metadata":{"id":"oSoPWwFl8Hlo"}},{"cell_type":"code","source":["fig, axes = plot_observed_vs_bayes_optimal_confidence(df)"],"metadata":{"id":"DjA3MmU8XTfH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 2B**"],"metadata":{"id":"Mds0l9qe8MJr"}},{"cell_type":"code","source":["fig, axes = plot_observed_vs_bayes_optimal_log_odds(df)"],"metadata":{"id":"6nlzm4aDX1gj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**TABLE 1**"],"metadata":{"id":"-Ljtiaqo8Ti7"}},{"cell_type":"code","source":["results = calc_overunderconfidence_score(df, expt_type=expt_type)"],"metadata":{"id":"a0hTbR5PhhBK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**FIGURE 2D**"],"metadata":{"id":"nYyauQj38Wir"}},{"cell_type":"code","source":["# Plot Opposite Hidden at 80% accuracy\n","fig, ax = plot_bayes_confidence_update_comparison(\n","    df,\n","    condition='Opposite',\n","    accuracy=80,\n","    display_type='hidden',\n","  )\n","\n","# Plot Same Hidden at 80% accuracy\n","fig, ax = plot_bayes_confidence_update_comparison(\n","    df,\n","    condition='Same',\n","    accuracy=80,\n","    display_type='hidden',\n",")\n"],"metadata":{"id":"vDnXOcYvZzB9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figures 3 and 4**"],"metadata":{"id":"gi7T9B8F800R"}},{"cell_type":"code","source":["# Opposite Hidden\n","fig, axes = plot_bayes_update_grid_all_accuracies(\n","    df,\n","    condition='Opposite',\n","    display_type='hidden',\n","    y_range=(-1.2, 0.4),\n","    y_tick_spacing=0.2,\n","    figsize=(16, 20)\n",")\n","\n","# For Same Hidden\n","fig, axes = plot_bayes_update_grid_all_accuracies(\n","    df,\n","    condition='Same',\n","    display_type='hidden',\n","    y_range=(0, 1),\n","    y_tick_spacing=0.2,\n","    figsize=(16, 20)\n",")"],"metadata":{"id":"A5nml7zRaWRV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 5B**"],"metadata":{"id":"dc6MdOqN87Bb"}},{"cell_type":"code","source":["expt_type = \"hog\" #note \"hog\" is Answer Wrong experiment\n","file_path = f\"{the_dir}gemma12b_answerwrong_experiment_data.csv\"\n","df = pd.read_csv(file_path)\n","df_no_nans = find_nan_in_df(df)\n","df = df_no_nans\n","\n","fig, axes = plot_answer_wrong_COM_composite(\n","    df\n",")\n"],"metadata":{"id":"9HbuQUagc1fG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**FIGURE 6A**"],"metadata":{"id":"C2R7pRQx9BY1"}},{"cell_type":"code","source":["expt_type = \"latitude\"\n","file_path = f\"{the_dir}gemma12b_latitude_otherllm_experiment_data.csv\"\n","df = pd.read_csv(file_path)\n","df_no_nans = find_nan_in_df(df)\n","df = df_no_nans\n","df = add_new_confidence_columns(df, expt_type)\n","fig, ax = plot_for_composite_CSB_COM_acrossmodels(df)\n","fig, ax =plot_for_composite_CSB_conf_acrossmodels(df)"],"metadata":{"id":"0iqJKQZMdAye"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Figure 6B**"],"metadata":{"id":"KsGFbh5ekv04"}},{"cell_type":"code","source":["expt_type = \"latitude\"\n","file_path = f\"{the_dir}Gemma12B_multiturn_latitude_experiment_data.csv\"\n","df = pd.read_csv(file_path)\n","df_no_nans = find_nan_in_df(df)\n","df = df_no_nans\n","df = add_new_confidence_columns(df, expt_type)\n","fig, ax = plot_for_composite_CSB_COM_acrossmodels(df)\n","fig, ax =plot_for_composite_CSB_conf_acrossmodels(df)\n"],"metadata":{"id":"TY0eAQy0jaOr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 5A**"],"metadata":{"id":"0e0Gom7hk6Z3"}},{"cell_type":"code","source":["expt_type = \"latitude\"\n","file_path = f\"{the_dir}Gemma12B_likelihood_latitude_experiment_data.csv\"\n","df = pd.read_csv(file_path)\n","df_no_nans = find_nan_in_df(df)\n","df = df_no_nans\n","df = add_new_confidence_columns(df, expt_type)\n","fig, ax = plot_for_composite_CSB_COM_acrossmodels(df)\n","fig, ax =plot_for_composite_CSB_conf_acrossmodels(df)"],"metadata":{"id":"hfO_LezWk0kG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 5C**"],"metadata":{"id":"-iN06GQe9FAO"}},{"cell_type":"code","source":["expt_type = \"latitude\"\n","file_path = f\"{the_dir}gemma12b_latitude_ICX_experiment_data.csv\"\n","df = pd.read_csv(file_path)\n","\n","df_no_nans = find_nan_in_df(df)\n","df = df_no_nans\n","df = df.rename(columns={'change_of_mind_actual':'change_of_mind'})\n","fig, axes = plot_change_of_mind_by_condition(df)"],"metadata":{"id":"Fz0EAvpfewoq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Gemma 3 27B"],"metadata":{"id":"grVpLtdAIWPM"}},{"cell_type":"code","source":["expt_type = \"latitude\"\n","file_path = f\"{the_dir}gemma27b_latitude_experiment_data.csv\"\n","df = pd.read_csv(file_path)"],"metadata":{"id":"mD5-4JPGImWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_no_nans = find_nan_in_df(df)\n","df = df_no_nans"],"metadata":{"id":"NzhteLakOglL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = add_new_confidence_columns(df, expt_type)\n","df = add_bayes_optimal_columns(df)"],"metadata":{"id":"lXR8E1NMOS1v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Figures 4 and 5**"],"metadata":{"id":"sDTy1yJGpQgK"}},{"cell_type":"code","source":["fig, ax = plot_for_composite_CSB_COM_acrossmodels(df)\n","fig, ax = plot_for_composite_CSB_conf_acrossmodels(df)\n","figs = plot_obs_bayes_pred_COM_allmodels(df)\n","fig, ax = plot_obs_bayes_pred_confidence_allmodels(df)"],"metadata":{"id":"lkQntDcNpP7c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 8A**"],"metadata":{"id":"y-EIRFUE9iT1"}},{"cell_type":"code","source":["fig, axes = plot_change_of_mind_by_condition(df)"],"metadata":{"id":"Utr5jE20PP-3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 8B**"],"metadata":{"id":"DNl0ytmP9l0q"}},{"cell_type":"code","source":["fig, axes = plot_confidence_change_by_condition(df)"],"metadata":{"id":"ZAILwiakQJfX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 8C**"],"metadata":{"id":"Wq5cgrOH9oNb"}},{"cell_type":"code","source":["fig, axes = plot_observed_vs_bayes_optimal_confidence(df)"],"metadata":{"id":"ch9veMVUXVfR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Table 7**"],"metadata":{"id":"28E4hM5n9sh0"}},{"cell_type":"code","source":["results = calc_overunderconfidence_score(df, expt_type=expt_type)"],"metadata":{"id":"Cemp3uGJhlKi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 8D**"],"metadata":{"id":"5QsHvsW29uMd"}},{"cell_type":"code","source":["# Plot Opposite Hidden at 80% accuracy\n","fig, ax = plot_bayes_confidence_update_comparison(\n","    df,\n","    condition='Opposite',\n","    accuracy=80,\n","    display_type='hidden',\n","  )\n","\n","# Plot Same Hidden at 80% accuracy\n","fig, ax = plot_bayes_confidence_update_comparison(\n","    df,\n","    condition='Same',\n","    accuracy=80,\n","    display_type='hidden',\n",")\n"],"metadata":{"id":"B0kW6jHZbPa3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GPT4o"],"metadata":{"id":"vFu6itMcIdBf"}},{"cell_type":"code","source":["expt_type = \"latitude\"\n","file_path = f\"{the_dir}GPT4o_difficult_latitude_experiment_data.csv\"\n","df = pd.read_csv(file_path)\n"],"metadata":{"id":"hy0FJKHcInAn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_no_nans = find_nan_in_df(df)\n","df = df_no_nans"],"metadata":{"id":"l4cDSz2JOhdB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = add_new_confidence_columns(df, expt_type)\n","df = add_bayes_optimal_columns(df)"],"metadata":{"id":"_gND5yK-OVII"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Figures 4 and 5**"],"metadata":{"id":"VvPuGA_DpZWu"}},{"cell_type":"code","source":["fig, ax = plot_for_composite_CSB_COM_acrossmodels(df)\n","fig, ax = plot_for_composite_CSB_conf_acrossmodels(df)\n","figs = plot_obs_bayes_pred_COM_allmodels(df)\n","fig, ax = plot_obs_bayes_pred_confidence_allmodels(df)"],"metadata":{"id":"luieJCfOpXwH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 9A**"],"metadata":{"id":"yKQBzDTD9zZs"}},{"cell_type":"code","source":["fig, axes = plot_change_of_mind_by_condition(df)"],"metadata":{"id":"P0byGNgOPQym"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 9B**"],"metadata":{"id":"zZsAk_7Q92oK"}},{"cell_type":"code","source":["fig, axes = plot_confidence_change_by_condition(df)"],"metadata":{"id":"BaC70D66QMYe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 9C**"],"metadata":{"id":"JyaJ-yvT95L-"}},{"cell_type":"code","source":["fig, axes = plot_observed_vs_bayes_optimal_confidence(df)"],"metadata":{"id":"in2_Thf9XW3I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Table 8**"],"metadata":{"id":"dNn5Cy0099BL"}},{"cell_type":"code","source":["results = calc_overunderconfidence_score(df, expt_type=expt_type)"],"metadata":{"id":"JpydZMN9hnZ5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 9D**"],"metadata":{"id":"C4Eh58oi9-ql"}},{"cell_type":"code","source":["# Plot Opposite Hidden at 80% accuracy\n","fig, ax = plot_bayes_confidence_update_comparison(\n","    df,\n","    condition='Opposite',\n","    accuracy=80,\n","    display_type='hidden',\n","  )\n","\n","# Plot Same Hidden at 80% accuracy\n","fig, ax = plot_bayes_confidence_update_comparison(\n","    df,\n","    condition='Same',\n","    accuracy=80,\n","    display_type='hidden',\n",")\n"],"metadata":{"id":"uIUieg8JbSQw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GPTo1-preview"],"metadata":{"id":"sZ7WsXFxIgEb"}},{"cell_type":"code","source":["expt_type = \"latitude\"\n","file_path = f\"{the_dir}GPT4o1preview_difficult_latitude_experiment_data.csv\"\n","df = pd.read_csv(file_path)\n"],"metadata":{"id":"Rt7lZ359Inmf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_no_nans = find_nan_in_df(df)\n","df = df_no_nans"],"metadata":{"id":"ptu2L2LyOV4Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extended Data Figure 10**"],"metadata":{"id":"0eoBL5mF-CrE"}},{"cell_type":"code","source":["fig, axes = plot_change_of_mind_by_condition(df)"],"metadata":{"id":"tWx7U5aXPSxq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Llama 70B Instruct"],"metadata":{"id":"0nXdoHKzlP-O"}},{"cell_type":"code","source":["expt_type = \"latitude\"\n","file_path = f\"{the_dir}llama70b_latitude_experiment_data.csv\"\n","df = pd.read_csv(file_path)\n","df_no_nans = find_nan_in_df(df)\n","df = df_no_nans\n","df = add_new_confidence_columns(df, expt_type)\n","df = add_bayes_optimal_columns(df)"],"metadata":{"id":"ngG_7SrjlN-U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Figure 4**"],"metadata":{"id":"QXS-fgP4l3SU"}},{"cell_type":"code","source":["fig, ax = plot_for_composite_CSB_COM_acrossmodels(df)\n","fig, ax = plot_for_composite_CSB_conf_acrossmodels(df)"],"metadata":{"id":"ElKNc-Qflg2g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Figure 5**"],"metadata":{"id":"1Bur0gHXl5pc"}},{"cell_type":"code","source":["figs = plot_obs_bayes_pred_COM_allmodels(df)\n","fig, ax = plot_obs_bayes_pred_confidence_allmodels(df)"],"metadata":{"id":"Z-LTy2A7lzfX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DeepSeek 671B"],"metadata":{"id":"eu4QC5TPIipA"}},{"cell_type":"code","source":["expt_type = \"latitude\"\n","file_path = f\"{the_dir}DeepSeek_671_latitude_experiment_data.csv\"\n","df = pd.read_csv(file_path)"],"metadata":{"id":"ge9TYGPtIoHy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_no_nans = find_nan_in_df(df)\n","df = df_no_nans\n","df = add_new_confidence_columns(df, expt_type)\n","df = add_bayes_optimal_columns(df)"],"metadata":{"id":"waPMhvl4OYZ3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Figure 4**"],"metadata":{"id":"ACg9lpkfmLIy"}},{"cell_type":"code","source":["fig, ax = plot_for_composite_CSB_COM_acrossmodels(df)\n","fig, ax = plot_for_composite_CSB_conf_acrossmodels(df)"],"metadata":{"id":"5g1QUikLmIFi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Figure 5**"],"metadata":{"id":"JEsy4iTVmTCa"}},{"cell_type":"code","source":["figs = plot_obs_bayes_pred_COM_allmodels(df)\n","fig, ax = plot_obs_bayes_pred_confidence_allmodels(df)"],"metadata":{"id":"WGuYhsJ-mSEl"},"execution_count":null,"outputs":[]}]}